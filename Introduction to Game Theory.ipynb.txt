{"payload":{"allShortcutsEnabled":true,"fileTree":{"Social Science":{"items":[{"name":".ipynb_checkpoints","path":"Social Science/.ipynb_checkpoints","contentType":"directory"},{"name":"Introduction to Game Theory.ipynb","path":"Social Science/Introduction to Game Theory.ipynb","contentType":"file"},{"name":"Introduction to Poker Theory.ipynb","path":"Social Science/Introduction to Poker Theory.ipynb","contentType":"file"}],"totalCount":3},"":{"items":[{"name":"Computer Science","path":"Computer Science","contentType":"directory"},{"name":"Finance","path":"Finance","contentType":"directory"},{"name":"Marketing","path":"Marketing","contentType":"directory"},{"name":"Mathematics and Statistics","path":"Mathematics and Statistics","contentType":"directory"},{"name":"Other","path":"Other","contentType":"directory"},{"name":"Social Science","path":"Social Science","contentType":"directory"},{"name":"Trading","path":"Trading","contentType":"directory"},{"name":"FILE.EXT","path":"FILE.EXT","contentType":"file"},{"name":"README.md","path":"README.md","contentType":"file"},{"name":"_config.yml","path":"_config.yml","contentType":"file"},{"name":"test.txt","path":"test.txt","contentType":"file"}],"totalCount":11}},"fileTreeProcessingTime":4.701988,"foldersToFetch":[],"reducedMotionEnabled":"system","repo":{"id":159648187,"defaultBranch":"master","name":"Private-Study-and-Research-Notes","ownerLogin":"dreadfullegion","currentUserCanPush":true,"isFork":false,"isEmpty":false,"createdAt":"2018-11-29T04:25:32.000-06:00","ownerAvatar":"https://avatars.githubusercontent.com/u/45304203?v=4","public":false,"private":true,"isOrgOwned":false},"refInfo":{"name":"master","listCacheKey":"v0:1687056189.94097","canEdit":true,"refType":"branch","currentOid":"28715bf1eaaa39becc1c47f69a82ce33debdc5d1"},"path":"Social Science/Introduction to Game Theory.ipynb","currentUser":{"id":45304203,"login":"dreadfullegion","userEmail":"marklau12138@gmail.com"},"blob":{"rawBlob":"{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Normal Form Game\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Definition\\n\",\n    \"\\n\",\n    \"In a $n$-player normal form game $G = (S_1, \\\\ldots, S_n; u_1, \\\\ldots, u_n)$, we define for $i = 1, \\\\ldots, n$,\\n\",\n    \"\\n\",\n    \"* $S_i$: a set of strategies for individual $i$\\n\",\n    \"* $(s_1, \\\\ldots, s_n) \\\\in S_1 \\\\times \\\\ldots \\\\times S_n $: a strategy profile\\n\",\n    \"* $u_i: (s_1, \\\\ldots, s_n) \\\\rightarrow \\\\mathbb{R}$: utility function for individual $i$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Classic Example: Prisoner's Dilemma\\n\",\n    \"\\n\",\n    \"One of the most famous example of normal game is [Prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner's_dilemma), where two prisoners are put into different rooms and cannot communicate with each other. Each prisoner is given two choices, to confess (**defect**), or to not confess (**cooporate**). Their jail time (**outcome**) will depend on their decisions.\\n\",\n    \"\\n\",\n    \"* If both prisoners confess, then each of them will serve 2 years behind bars.\\n\",\n    \"* If both prisoners do not confess, then each of them will serve 1 year behind bars.\\n\",\n    \"* If prisoner A confesses while prisoner B do not confess, then prisoner A is set free while prisoner B will serve 3 years in prison and vice versa.\\n\",\n    \"\\n\",\n    \"We will summarise these in a table (often coined the **payoff** table).\\n\",\n    \"\\n\",\n    \"\\n\",\n    \"| *                       | Prisoner B cooporates | Prisoner B defects    |\\n\",\n    \"|-------------------------|-----------------------|-----------------------|\\n\",\n    \"| Prisoner A cooporates   |       (-1, -1)        |       (-3, 0)         |\\n\",\n    \"| Prisoner A defects      |       (0, -3)         |       (-2, -2)        |\\n\",\n    \"\\n\",\n    \"This is an example of normal form game with \\n\",\n    \"\\n\",\n    \"* $n = 2$: two players game\\n\",\n    \"* $S_i = \\\\{ \\\\text{confess}, \\\\hspace{2mm} \\\\text{not confess} \\\\}, \\\\hspace{2mm} i = 1, 2$: binary strategy\\n\",\n    \"\\n\",\n    \"And the utility function is specified in the form of the payoff table. For example, for $i = 1, 2$,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i ( s_1 = \\\\text{confess}, \\\\hspace{1mm}  s_2 = \\\\text{confess} ) = -1.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Assumptions\\n\",\n    \"\\n\",\n    \"* Players have common knowledge about the struture of the game\\n\",\n    \"* Players choose their strategies independently\\n\",\n    \"* If players can costlessly communicate, then the message they send are part of their strategies and the game specifies what messages can be sent\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Nash Equilibrium\\n\",\n    \"\\n\",\n    \"Game theory is aimed to identify at least one solution for every game, where a solution is defined as a set of recommendations, one for each player, where no player has any incentive to not follow these recommendations. One possible solution is **Nash equilibrium**.\\n\",\n    \"\\n\",\n    \"A Nash equilibrium is a strategy profile such that no player has an incentive to *unilaterally* deviate from his strategy. More formally, the strategy profile $s^* = \\\\left( s^*_1, \\\\ldots, s^*_n \\\\right) \\\\in S$ is a Nash equilibrium of a game $G(S_1, \\\\ldots, S_n; u_1, \\\\ldots, u_n)$ if for each $i = 1, \\\\ldots, n$, \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i \\\\left( s^*_1, \\\\ldots, s^*_i, \\\\ldots, s^*_n \\\\right) \\\\geq u_i \\\\left( s^*_1, \\\\ldots, s_i, \\\\ldots, s^*_n \\\\right)\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"for every $s_i \\\\in S_i$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Best Response and Alternative Definition of Nash Equilibrium\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Best Response\\n\",\n    \"\\n\",\n    \"Consider a $n$-player game $G(S_1, \\\\ldots, S_n; u_1, \\\\ldots, u_n)$, the set of player $i$'s **best response** against $S_{-i} = (s_1, \\\\ldots, s_{i-1}, s_{i+1}, \\\\ldots, s_n)$ is a set of strategies $R_i (S_{-i})$ such that \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  R_i \\\\left( S_{-i} \\\\right) = \\\\arg \\\\max_{s_i \\\\in S_i} u_i (s_1, \\\\ldots, s_{i-1}, s_i, s_{i+1},\\\\ldots, s_n )\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Alternative Definition of Nash Equilibrium\\n\",\n    \"\\n\",\n    \"The strategy profile $\\\\left( s^*_1, \\\\ldots, s^*_n \\\\right)$ is a Nash equilibrium if and only if for every $i = 1, \\\\ldots, n$ we have $s^*_i \\\\in R_i \\\\left( S^*_{-i} \\\\right)$ where $S^*_{-i} = \\\\left(s^*_1, \\\\ldots, s^*_{i-1}, s^*_{i+1}, \\\\ldots, s^*_n \\\\right)$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Examples\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Prisoner's Dilemma\\n\",\n    \"\\n\",\n    \"Recall the payoff table for prisoner's dilemma\\n\",\n    \"\\n\",\n    \"| *                       | Prisoner B cooporates | Prisoner B defects    |\\n\",\n    \"|-------------------------|-----------------------|-----------------------|\\n\",\n    \"| Prisoner A cooporates   |       (-1, -1)        |       (-3, 0)         |\\n\",\n    \"| Prisoner A defects      |       (0, -3)         |       (-2, -2)        |\\n\",\n    \"\\n\",\n    \"then the best responses for each individual and each strategy profile are\\n\",\n    \"\\n\",\n    \"* $R_A$ (cooporate) = {defect}\\n\",\n    \"* $R_A$ (defect) = {defect}\\n\",\n    \"* $R_B$ (cooporate) = {defect}\\n\",\n    \"* $R_B$ (defect) = {defect}\\n\",\n    \"\\n\",\n    \"It is easy to see that regardless of what the other prisoner do, each prisoner is always better off if the individual chooses to defect (or to confess). So the only mutual best response is $\\\\{ (\\\\text{defect}, \\\\hspace{1mm} \\\\text{defect})\\\\}$. Then, the Nash equilibrium is \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\{ (\\\\text{defect}, \\\\hspace{1mm} \\\\text{defect})\\\\}.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Battle of the Sexes\\n\",\n    \"\\n\",\n    \"Sometimes there can be more than one Nash equilibriums. In another classic example, the [battle of the sexes](https://en.wikipedia.org/wiki/Battle_of_the_sexes_(game_theory)), which have payoff matrix as follows.\\n\",\n    \"\\n\",\n    \"| *                           | Husband chooses opera (O) | Husband chooses football (F) |\\n\",\n    \"|-----------------------------|---------------------------|------------------------------|\\n\",\n    \"| Wife chooses opera (O)      |          (3, 2)           |           (0, 0)             |\\n\",\n    \"| Wife chooses football (F)   |          (0, 0)           |           (2, 3)             |\\n\",\n    \" \\n\",\n    \"In this example, both husband and wife agreed to meet but neither remembers whether they should attend opera or football (the fact that they forgot is **common knowledge**, i.e. both of them knows each other also forgot). Husband would prefer to go to football where wife would perfer to go to opera. Then, the best responses are\\n\",\n    \"\\n\",\n    \"* $R_{\\\\text{husband}} (O) = \\\\{O\\\\}$\\n\",\n    \"* $R_{\\\\text{husband}} (F) = \\\\{F\\\\}$\\n\",\n    \"* $R_{\\\\text{wife}} (O) = \\\\{O\\\\}$\\n\",\n    \"* $R_{\\\\text{wife}} (F) = \\\\{F\\\\}$\\n\",\n    \"\\n\",\n    \"and hence there are two mutual best responses $\\\\{ (O, O), (F, F) \\\\}$ and hence the Nash equilibriums is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\{ (O, O), (F, F) \\\\}.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Indifference\\n\",\n    \"\\n\",\n    \"Now, suppose the football is cancelled and the payoff matrix has been changed to\\n\",\n    \"\\n\",\n    \"| *                           | Husband chooses opera (O) | Husband chooses football (F) |\\n\",\n    \"|-----------------------------|---------------------------|------------------------------|\\n\",\n    \"| Wife chooses opera (O)      |          (1, 1)           |           (0, 0)             |\\n\",\n    \"| Wife chooses football (F)   |          (0, 0)           |           (0, 0)             |\\n\",\n    \"\\n\",\n    \"where both husband and wife prefer to go to opera. Then, the best responses are\\n\",\n    \"\\n\",\n    \"* $R_{\\\\text{husband}} (O) = \\\\{O\\\\}$\\n\",\n    \"* $R_{\\\\text{husband}} (F) = \\\\{O, F\\\\}$\\n\",\n    \"* $R_{\\\\text{wife}} (O) = \\\\{O\\\\}$\\n\",\n    \"* $R_{\\\\text{wife}} (F) = \\\\{O, F\\\\}$\\n\",\n    \"\\n\",\n    \"where in the case of indifference (where both strategies give the same utilities, e.g. $u_{\\\\text{wife}}(O, F) = u_{\\\\text{wife}}(F, F) = 0$), we includes both strategies as our best responses. Hence, matching mutual best responses, our Nash equilibrium would still remain the same\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\{ (O, O), (F, F) \\\\}.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Matching Pennies\\n\",\n    \"\\n\",\n    \"Let us consider another classic example, the [matching pennies](https://en.wikipedia.org/wiki/Matching_pennies). The game is played by two players whom each have a penny and must secretly turn the penny to heads or tails. Then each player must reveal their choices simultanously and player 1 wins if the pennies match whereas player 2 wins if the pennies do not match. The winner gets to keep both pennies. Hence, the payoff matrix representing this game is as follows\\n\",\n    \"\\n\",\n    \"| *           | H       | T       |\\n\",\n    \"|-------------|---------|---------|\\n\",\n    \"| H           | (1, -1) | (-1, 1) |\\n\",\n    \"| T           | (-1, 1) | (1, -1) |\\n\",\n    \"\\n\",\n    \"where the row player is player 1 and the column player is player 2. Then the best responses are\\n\",\n    \"\\n\",\n    \"* $R_1 (H) = H$\\n\",\n    \"* $R_1 (T) = T$\\n\",\n    \"* $R_2 (H) = T$\\n\",\n    \"* $R_2 (T) = H$\\n\",\n    \"\\n\",\n    \"and it is easy to see that there are no mutual best responses. As such, this game has no **pure strategy** Nash equilibrium. We will define the term pure strategy in the next section.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Mixed Strategies\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Introduction\\n\",\n    \"\\n\",\n    \"A **pure strategy** provides complete definition of how a player will play a game. That is, it determines the move the player will make regardless of what moves do the other players make. \\n\",\n    \"\\n\",\n    \"If we allow players to randomly select between pure strategies by assigning probabilities to each pure strategies, then this becomes a **mixed strategy**. \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Matching Pennies Example\\n\",\n    \"\\n\",\n    \"To apply mixed strategy in the matching pennies example mentioned in [1.6.4](#1.6.4-matching-pennies), let $x \\\\in [0, 1]$ be the probability of player 1 selecting head ($H$), and let $y \\\\in [0, 1]$ be the probability of player 2 selecting head ($H$).\\n\",\n    \"\\n\",\n    \"| *           | H       | T       |\\n\",\n    \"|-------------|---------|---------|\\n\",\n    \"| H           | (1, -1) | (-1, 1) |\\n\",\n    \"| T           | (-1, 1) | (1, -1) |\\n\",\n    \"\\n\",\n    \"Then the utility functions for player 1 given the probability of player 2 choosing a head (i.e. given $y$) is\\n\",\n    \"\\n\",\n    \"* $u_1 (H, y) = y \\\\times (1) + (1 - y) \\\\times (-1) = 2y - 1 > 0$ if $y > \\\\frac{1}{2}$,\\n\",\n    \"* $u_1 (T, y) = y \\\\times (-1) + (1 - y) \\\\times (1) = 1 - 2y > 0$ if $y < \\\\frac{1}{2}$,\\n\",\n    \"\\n\",\n    \"and hence player 1's best response given $y$ is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  R_1 (y) = \\\\begin{cases}\\n\",\n    \"              x = 0 & \\\\text{if} & 0 \\\\leq y < \\\\frac{1}{2},\\\\\\\\\\n\",\n    \"              x \\\\in [0, 1] & \\\\text{if} & y = \\\\frac{1}{2},\\\\\\\\\\n\",\n    \"              x = 1 & \\\\text{if} & \\\\frac{1}{2} < y \\\\leq 1.\\n\",\n    \"            \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Similarily, player 2's best response given $x$ is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  R_2 (x) = \\\\begin{cases}\\n\",\n    \"              y = 1 & \\\\text{if} & 0 \\\\leq x < \\\\frac{1}{2},\\\\\\\\\\n\",\n    \"              y \\\\in [0, 1] & \\\\text{if} & x = \\\\frac{1}{2},\\\\\\\\\\n\",\n    \"              y = 0 & \\\\text{if} & \\\\frac{1}{2} < x \\\\leq 1.\\n\",\n    \"            \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Now, we shall plot the best response functions together.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"metadata\": {\n    \"hide_input\": true\n   },\n   \"outputs\": [\n    {\n     \"data\": {\n      \"image/png\": \"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\\n\",\n      \"text/plain\": [\n       \"<Figure size 432x288 with 1 Axes>\"\n      ]\n     },\n     \"metadata\": {\n      \"needs_background\": \"light\"\n     },\n     \"output_type\": \"display_data\"\n    }\n   ],\n   \"source\": [\n    \"%matplotlib inline\\n\",\n    \"import matplotlib.pyplot as plt;\\n\",\n    \"x1 = [0, 1, 1]; x2 = [0, 0.5, 1]; y1 = [0, 0.5, 1]; y2 = [1, 1, 0];\\n\",\n    \"plt.step(x1, y1, label = \\\"R_1 (y)\\\"); plt.step(x2, y2, label = \\\"R_2 (x)\\\"); plt.show; \\n\",\n    \"plt.legend(); plt.title(\\\"Best Response Graph\\\"); plt.xlabel(\\\"x\\\"); plt.ylabel(\\\"y\\\");\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"The Nash equilibrium is the point where $R_1(y)$ and $R_2(x)$ meet, which corresponds to $x = \\\\frac{1}{2}$ and $y = \\\\frac{1}{2}$. That is,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\left\\\\{ \\\\left(\\\\frac{1}{2} H + \\\\frac{1}{2} T, \\\\frac{1}{2} H + \\\\frac{1}{2} T \\\\right) \\\\right\\\\}.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Formal Definition\\n\",\n    \"\\n\",\n    \"#### Mixed Strategy Nash Equilibrium\\n\",\n    \"\\n\",\n    \"A mixed strategy for player $i$ is a probability distribution $p_i$ over his set of pure strategies $S_i$. The mixed strategy profile $p^* = \\\\left( p^*_1, \\\\ldots, p^*_n \\\\right)$ is a Nash equilibrium of $G$ if for each $i = 1, \\\\ldots, n$\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i \\\\left( p^*_1, \\\\ldots, p^*_{i-1}, p^*_i, p^*_{i+1} ,\\\\ldots, p^*_n \\\\right) \\\\geq u_i \\\\left( p^*_1, \\\\ldots, p^*_{i-1}, p_i, p^*_{i+1} ,\\\\ldots, p^*_n \\\\right)\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"for all mixed strategies $p_i$ avaliable to player $i$.\\n\",\n    \"\\n\",\n    \"It can be proved that [every game with finite number of players and pure strategies has at least one Nash equilibrium](https://www.cs.ubc.ca/~jiang/papers/NashReport.pdf).\\n\",\n    \"\\n\",\n    \"#### Mixed Strategy Best Responses\\n\",\n    \"\\n\",\n    \"Similar to pure strategy, we define the set of player $i$'s best responses against $p_{-i} = (p_1, \\\\ldots, p_{i-1}, p_{i+1}, \\\\ldots, p_n)$ as the set\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  R_i (p_{-i}) = \\\\arg \\\\max_{p_i} u_i (p_1, \\\\ldots, p_{i-1}, p_i, p_{i+1}, \\\\ldots, p_n). \\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"And the strategy profile $\\\\left( p^*_1, \\\\ldots, p^*_n \\\\right)$ is a Nash equilibrium if for every $i = 1, \\\\ldots, n$, we have $p^*_i \\\\in R_i (p_{-i})$.  \\n\",\n    \"\\n\",\n    \"#### A Quick Note on Notation\\n\",\n    \"\\n\",\n    \"Note that we often use the notation\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i (p_i, p_{-i}) = u_i (p_1, \\\\ldots, p_{i-1}, p_i, p_{i+1}, \\\\ldots, p_n)\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"to shorten the expression. In some literatures, we use the more rigorous notation $\\\\mathbb{E} u_i(s_i, p_{-i})$ to represent the **expected** utility when $i$ plays $s_i$ given $-i$ (i.e. players other than $i$) play $p_{-i}$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Proposition about Mix Strategies\\n\",\n    \"\\n\",\n    \"If a mixed strategy is a best response, then each of the pure strategies involved in the mix must itself be a best response. In particular, each must yield the same expected payoff.\\n\",\n    \"\\n\",\n    \"More formally, if player $i$'s mixed strategy $p_i$ is a best response to the (mixed) strategies of other players $p_{-i}$, then, for each pure strategy $s_i$ in the support of $p_i$ (that is, $p_i(s_i) > 0$), it must be the case that $s_i$ is itself a best response to $p_{-i}$. in particular, $\\\\mathbb{E} u_i(s_i, p_{-i})$ must be the same for all such strategies.\\n\",\n    \"\\n\",\n    \"####  Proof of Statement\\n\",\n    \"\\n\",\n    \"Suppose the converse of the above statement, that is, if $p_i \\\\in R_i (p_{-i})$ is a best response against $p_{-i}$ and there exists at least one $s_i \\\\in S_i$ in the support of $p_i$ such that $s_i \\\\notin R_i (p_{-i})$ is not the best response. That is,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\mathbb{E} u_i (s_i, p_{-i}) <  \\\\mathbb{E} u_i (s'_i, p_{-i})\\n\",\n    \"$$ \\n\",\n    \"\\n\",\n    \"for some pure strategy profile $s'_i \\\\in S_i$ or some mixed strategy profile $s'_i$. Then if player $i$ updates her strategy $p_i$ to $p'_i$ by simply swapping $s_i$ with $s'_i$ while holding all other mix the same, then it is easy to see that \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\mathbb{E} u_i (p_i, p_{-i}) <  \\\\mathbb{E} u_i (p'_i, p_{-i}),\\n\",\n    \"$$ \\n\",\n    \"\\n\",\n    \"which contradicts our assumption that $p_i$ is a best response to $p_{-i}$. Hence, we must have $s_i \\\\in R_i (p_{-i})$ for all $s_i$ in the support of $p_i$ and thus by definition, $\\\\mathbb{E} u_i(s_i, p_{-i})$ must be the same for all such strategies.\\n\",\n    \"\\n\",\n    \"####  Some Implications\\n\",\n    \"\\n\",\n    \"This observation has sparked some critic on mix strategy equilibrium:\\n\",\n    \"\\n\",\n    \"> \\\"What compels a player, when indifferent among some of his pure strategies, to randomise over them precisely so as to make the other players indifferent among some of their pure strategies?\\\"\\n\",\n    \"\\n\",\n    \"Harsanyi (1973) provides an intuitive answer to the above critic using the **purification theorem**, which we will explore later.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Stable Equilibrium\\n\",\n    \"\\n\",\n    \"One more concept about mixed strategies is its stability. Before formalise stability, we will first introduce some related concepts. Note that the notation used in this section is defined in **2.1**. I must apologise here for the inconsistent use of notations in this notebook.\\n\",\n    \"\\n\",\n    \"#### Totally Mixed Strategies\\n\",\n    \"\\n\",\n    \"Player $i$'s **totally** mixed strategies are mixed strategies $\\\\sigma_i \\\\in \\\\Delta_i$ such that every pure strategy $s_i \\\\in S_i$ is in the support of $\\\\sigma_i$. That is,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\sigma_i (s_i) > 0 \\\\hspace{5mm} \\\\forall \\\\hspace{2mm} s_i \\\\in S_i.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"####  Perturbed Game\\n\",\n    \"\\n\",\n    \"A perturbed game is a copy of the base game, with the restriction that only totally mixed strategies are allowed to be played. \\n\",\n    \"\\n\",\n    \"This is also known as the \\\"trembling hands\\\" of the players, where they sometimes make mistake and play a different strategy other than the one they intend to play. This restriction allows the game to more realisticly model real world problems. \\n\",\n    \"\\n\",\n    \"#### Stable Equilibrium\\n\",\n    \"\\n\",\n    \"A Nash equilibrium for a mixed strategy $\\\\sigma = (\\\\sigma_1, \\\\ldots, \\\\sigma_I) \\\\in \\\\Delta = \\\\Delta_i \\\\times \\\\ldots \\\\Delta_I$ is stable if a small change or perturbation $\\\\epsilon > 0$ (specifically, an infinitesimal change $\\\\epsilon \\\\rightarrow 0$) in probabilities $\\\\sigma_i (s_i)$ for some strategies $s_i \\\\in S_i$ in the mix and for some player $i$ leads to a situation where two conditions hold:\\n\",\n    \"\\n\",\n    \"* the players $-i$ who did not change has no better strategy in the new circumstance against player $i$'s perturbed strategy $\\\\sigma'_i$:\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"    \\\\sigma_{-i} \\\\in R_{-i} (\\\\sigma'_i);\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"* the player $i$ who did change is now playing with a strictly worse strategy:\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"    \\\\sigma_i \\\\notin R_i (\\\\sigma_{-i}).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Hence, if the two conditions are met, the player $i$ with the small change in their mixed strategy $\\\\sigma'_i$ will return immediately to the Nash equilibrium strategy $\\\\sigma_i$\\n\",\n    \"\\n\",\n    \"Intuitively, we can see that stable equilibriums are less sensitive to small mistakes (perturbations) from each of the players involved. This is particularly important when players are not certain of others' rationalities.\\n\",\n    \"\\n\",\n    \"#### Example: Coordination Game\\n\",\n    \"\\n\",\n    \"Coordination game is a game between two players which each player would receive a better payoff if they choose the same action. A example normal form representation of the game is given below.\\n\",\n    \"\\n\",\n    \"|   *   | left | right |\\n\",\n    \"|-------|------|-------|\\n\",\n    \"| left  | 5, 5 |  0, 0 |\\n\",\n    \"| right | 0, 0 |  5, 5 |\\n\",\n    \"\\n\",\n    \"If we let $L$ denote *left* and $R$ denote *right*, then it is easy to check that the game has three (mixed) Nash equilibrias\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\left\\\\{ (L, L), \\\\left( \\\\frac{1}{2}L + \\\\frac{1}{2}R, \\\\frac{1}{2}L + \\\\frac{1}{2}R \\\\right), (R, R) \\\\right\\\\}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"It is not difficult to check that both pure strategy Nash equilibrias are stable while the totally mixed Nash equilibria is not. Stability is crucial in practical application of Nash equilibrium.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Dominated Strategy and Admissibility\\n\",\n    \"\\n\",\n    \"In games with large set of strategies, we often look for ways to narrow down the candidate strategies. If one strategy is unequivocally better than another strategy, that is, the first strategy gives a larger payoff than the second strategy **no matter what the other players do**, then the player has no incentive to choose the second strategy over the first strategy. As such, we say the first strategy **dominates** the second strategy. We will introduce this concept more formally in the next few sections.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Strictly Dominated Strategy\\n\",\n    \"\\n\",\n    \"Given a game $G$, we say the (mixed) strategy $p_i$ is strictly dominated by $p'_i \\\\neq p_i$ if, for every pure strategy profile of the opponents $s_{-i} = (s_1, \\\\ldots, s_n) \\\\in S_{-i}$, we have \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i (s_1, \\\\ldots, s_{i-1}, p_i, s_{i+1}, \\\\ldots, s_n) < u_i (s_1, \\\\ldots, s_{i-1}, p'_i, s_{i+1}, \\\\ldots, s_n).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Intuitively, if a strategy is strictly dominated, then it will never be used in a Nash equilibrium. As such, we have the following theorem.\\n\",\n    \"\\n\",\n    \"####  Theorem\\n\",\n    \"\\n\",\n    \"> Let $G$ be an $n$-player normal form game such that player $i$ has a strictly dominated strategy $p_i$ in $G$. Let $G'$ be the $n$-player normal form game that is obtained from $G$ by removing $p_i$. Then $G$ and $G'$ have the same set of Nash equilibria.\\n\",\n    \"\\n\",\n    \"The direct implication is that if a pure strategy $s_i$ is strictly dominated, then upon removing this pure strategy $s_i$, the Nash equilibria does not change.\\n\",\n    \"\\n\",\n    \"####  Example\\n\",\n    \"\\n\",\n    \"Consider the following normal form game.\\n\",\n    \"\\n\",\n    \"| *           | A      | B      |C       |\\n\",\n    \"|-------------|--------|--------|--------|\\n\",\n    \"| **a**       | (4, 4) | (3, 3) | (2, 2) |\\n\",\n    \"| **b**       | (3, 3) | (2, 2) | (1, 1) |\\n\",\n    \"| **c**       | (2, 2) | (1, 1) | (0, 0) |\\n\",\n    \"\\n\",\n    \"We can easily see that, for the column player, $C$ is dominated by $B$ and $B$ is dominated by $A$. Similarily, for the row player, both $b$ and $c$ are dominated by $a$. If we follow our usual approach of finding the Nash equilibria, we will eventually reach to the following conclusion:\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\{ (a, A) \\\\}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Applying the above theorem, if we remove the strictly dominated strategies, we have \\n\",\n    \"\\n\",\n    \"| *     | A      |\\n\",\n    \"|-------|--------|\\n\",\n    \"| **a** | (4, 4) |\\n\",\n    \"\\n\",\n    \"and the Nash equilibrium is trivially\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\{ (a, A) \\\\}.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Weakly Dominated Strategy\\n\",\n    \"\\n\",\n    \"The strategy $p_i$ is weakly dominated by $p'_i$ if $p'_i$ is always at least as good as $p_i$ and sometimes strictly better whatever the other players play. \\n\",\n    \"\\n\",\n    \"More formally, given a game $G$, we say $p_i$ is *weakly dominated* by $p'_i$ if for all pure strategy profiles of the opponenets $s_{-i} = (s_1, \\\\ldots, s_{i-1}, s_{i+1}, \\\\ldots, s_n) \\\\in S_{-i}$, we have\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i (s_{-i}, p_i) \\\\leq u_i \\\\left( s_{-i}, p'_i \\\\right),\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"and there exists at least one pure strategy profile $s'_{-i} \\\\in S_{-i}$ such that \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i \\\\left(s'_{-i}, p_i \\\\right) < u_i \\\\left( s'_{-i}, p'_i \\\\right).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"####  Example\\n\",\n    \"\\n\",\n    \"Consider the same indifference example as in 1.6.3.\\n\",\n    \"\\n\",\n    \"| *                           | Husband chooses opera (O) | Husband chooses football (F) |\\n\",\n    \"|-----------------------------|---------------------------|------------------------------|\\n\",\n    \"| Wife chooses opera (O)      |          (1, 1)           |           (0, 0)             |\\n\",\n    \"| Wife chooses football (F)   |          (0, 0)           |           (0, 0)             |\\n\",\n    \"\\n\",\n    \"We can see that $O$ weakly dominates $F$. However, the Nash equilibrium of this example is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\{ (O, O), (F, F) \\\\}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Therefore, we can not remove weakly dominated strategies when finding Nash equilibrium. Nevertheless, there is still no incentives for player to choose $F$ over $O$. Hence, we have the *admissibility* principle.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Proposition about Weakly Dominance\\n\",\n    \"\\n\",\n    \"Suppose there are $n$ actions (pure strategies) $A = \\\\{ A_1, \\\\ldots, A_n \\\\}$. If a mixed strategy $\\\\alpha = \\\\{\\\\alpha_1, \\\\ldots, \\\\alpha_k\\\\}$, where $k < n$ and $\\\\alpha_j > 0$ is the probability for the player to choose action $j$, over a set of actions $A_1, \\\\ldots, A_k$ is weakly dominated. Then any mixed strategy $\\\\gamma$ that assigns stictly positive probabilities to actions $A_1, \\\\ldots, A_k$ is also weakly dominated.\\n\",\n    \"\\n\",\n    \"#### Proof\\n\",\n    \"\\n\",\n    \"In an $I$ player normal form game with total mixed strategies, let \\n\",\n    \"* $A_i = \\\\{A_{i1}, \\\\ldots, A_{i n_i}\\\\}$ be a set of actions (pure strategies) for player $i$, and let \\n\",\n    \"* $\\\\pi(s_{-i}) = \\\\{ \\\\pi_{ij} (s_{-i}) \\\\vert 0 \\\\leq j \\\\leq n_i, 0 \\\\leq i \\\\leq I\\\\}$ be a set of payoffs when player $i$ plays action $j$ against strategy profile $s_{-i} \\\\in S_{-i}$ of other players,\\n\",\n    \"\\n\",\n    \"Suppose the strategy $\\\\alpha = \\\\{ \\\\alpha_1, \\\\ldots, \\\\alpha_{k} \\\\}$, where $k < n_i$ and $\\\\alpha_j > 0$ is the probability for player $i$ to choose action $j$ under mixed strategy $\\\\alpha$, is weakly dominated by another player $i$'s strategy $\\\\beta = \\\\{ \\\\beta_1, \\\\ldots, \\\\beta_{n_i} \\\\}$. Assuming more is better, we know\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\mathbb{E} u_1 (\\\\alpha \\\\hspace{1mm} ; s_{-i}) \\\\leq \\\\mathbb{E} u_1 (\\\\beta \\\\hspace{1mm} ; s_{-i}) \\\\hspace{5mm} \\\\forall \\\\hspace{2mm} s_{-i} \\\\in S_{-i},\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"where the inequality is strict for some $s'_{-i} \\\\in S_{-i}$. \\n\",\n    \"\\n\",\n    \"Then, for any mixed strategy by player $i$: $\\\\gamma = \\\\{\\\\gamma_1, \\\\ldots, \\\\gamma_{n_i} \\\\vert \\\\gamma_1 > 0, \\\\ldots, \\\\gamma_{k} > 0 \\\\}$, let $\\\\tau > 0$ be some number such that $\\\\gamma_j - \\\\tau \\\\alpha_j > 0$ for all $j = 1, \\\\ldots, k$. We have\\n\",\n    \"\\n\",\n    \"\\n\",\n    \"\\\\begin{align*}\\n\",\n    \"  \\\\mathbb{E} u_i (\\\\gamma \\\\hspace{1mm} ; s_{-i}) &= \\\\sum_{j = 1}^n \\\\gamma_j \\\\pi_{ij} (s_{-i})\\\\\\\\ \\n\",\n    \"                                  &= \\\\tau \\\\sum_{j = 1}^k \\\\alpha_j \\\\pi_{ij} (s_{-i}) + \\\\sum_{j = 1}^k (\\\\gamma_j - \\\\tau \\\\alpha_j) \\\\pi_{ij} (s_{-i}) + \\\\sum_{j = k + 1}^{n_{i}} \\\\gamma_j \\\\pi_{ij} (s_{-i})\\\\\\\\\\n\",\n    \"                                  &= \\\\tau \\\\mathbb{E} u_i (\\\\alpha \\\\hspace{1mm} ; s_{-i}) + C\\\\\\\\\\n\",\n    \"                                  &\\\\leq \\\\tau \\\\mathbb{E} u_i (\\\\beta \\\\hspace{1mm} ; s_{-i}) + C,\\n\",\n    \"\\\\end{align*}\\n\",\n    \"\\n\",\n    \"\\n\",\n    \"for all $s_{-i} \\\\in S_{-i}$ where \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"    C = \\\\sum_{j = 1}^k (\\\\gamma_j - \\\\tau \\\\alpha_j) \\\\pi_{ij} (s_{-i}) + \\\\sum_{j = k + 1}^{n_{i}} \\\\gamma_j \\\\pi_{ij} (s_{-i}) > 0\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"and the inequality is strict against the strategy profile $s'_{-i}$ of $i$'s opponents. Hence, $\\\\gamma$ is also weakly dominated. \\n\",\n    \"\\n\",\n    \"Moreover, we see that $\\\\tau$ does not exist only when there exist some $j \\\\in \\\\{1, \\\\ldots, k\\\\}$ such that $\\\\gamma_j = 0$. \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Admissibility\\n\",\n    \"\\n\",\n    \"> Players should not use either strictly or weakly dominated strategies.\\n\",\n    \"\\n\",\n    \"Moreover, in example 1.8.2.1, we say that $(O, O)$ is the unique admissible (undominated) Nash equilibrium.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Application\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Cournot Model of Duopoly\\n\",\n    \"\\n\",\n    \"####  Assumptions\\n\",\n    \"\\n\",\n    \"* There are two firms, 1 and 2, competing in a duopolistic market.\\n\",\n    \"* These firms produce identical goods.\\n\",\n    \"* These firms simultanously decide the quantities, $q_1$ and $q_2$ respectively, that they will produce.\\n\",\n    \"* The market clearing price $p$ when there are total of $Q = q_1 + q_2$ goods is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  p = \\\\begin{cases}\\n\",\n    \"        a - Q & \\\\text{if} \\\\hspace{2mm} Q < a, \\\\\\\\\\n\",\n    \"        0 & \\\\text{otherwise}.\\n\",\n    \"      \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"* The cost of producing each good is $c < a$.\\n\",\n    \"\\n\",\n    \"####  Normal Form\\n\",\n    \"\\n\",\n    \"We can convert this setting to a setting of a two player normal game. The players are firm 1 and 2 and their strategies are producing $q_1, q_2 \\\\in [0, \\\\infty)$ units of good. For $i = 1, 2,$ the payoff function is then given by\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\pi_i (q_1, q_2) =  pq_i - cq_i = \\\\begin{cases}\\n\",\n    \"                                      (a - q_1 - q_2) q_i - c q_i & \\\\text{if} \\\\hspace{2mm} q_1 + q_2 < a,\\\\\\\\\\n\",\n    \"                                      - c q_i & \\\\text{otherwise}.\\n\",\n    \"                                    \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Note that if $q_i > a - c$, then $p < c$ and $\\\\pi_i (q_i, q_j) = (p - c) q_i< 0$, where $q_j$ is the quantity of the same goods produced by the other firm. Hence, there is no incentive for firm $i$ to produce goods at a quantity $q_i > a - c$. Moreover, if $q_2 = a - c$, then \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\pi_1 (q_1, q_2) = \\\\begin{cases}\\n\",\n    \"                          -q_1^2 & \\\\text{if} \\\\hspace{2mm} q_1 + q_2 < a,\\\\\\\\\\n\",\n    \"                          -c q_1 & \\\\text{otherwise},\\n\",\n    \"                        \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"which is never positive. So firm 1 should not produce any good and the market will be monopolise by firm 2. Similarily, if $q_1 = a - c$, then $\\\\pi_2 (q_1, q_2) \\\\leq 0$ and firm 1 will monopolise the market.\\n\",\n    \"\\n\",\n    \"Knowing this, if both firms try to produce $q_1 = q_2 = a - c$, then both firms have negative payoff and soon has to reach an agreement that neither firm should produce at a quantity that is higher or equal to $a - c$ to sustain their business operation. Hence, for the following sections, we assume $q_1, q_2 < a - c$.\\n\",\n    \"\\n\",\n    \"#### Best Response\\n\",\n    \"\\n\",\n    \"Based on the payoff function, if we fix the other firm's production quantity $q_j < a$, then firm $i$ ($i \\\\neq j$) needs to choose $q_i$ such that \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  q_i = \\\\arg \\\\max_{q_i} (a - q_1 - q_2)q_i - cq_i = \\\\arg \\\\max_{q_i} (a - c - q_j)q_i - q_i^2. \\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Hence, the best response against $q_j$ is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  R_i(q_j) = \\\\frac{1}{2} (a - c - q_j).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"####  Nash Equilibrium\\n\",\n    \"\\n\",\n    \"Therefore, the profile $\\\\left( q^*_1, q^*_2 \\\\right)$ is a Nash equilibrium if it solves \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  2 q^*_1 = a - c - q^*_2,\\\\\\\\\\n\",\n    \"  2 q^*_2 = a - c - q^*_1.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Thus, the solution is \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  q^*_1 = q^*_2 = \\\\frac{a - c}{3} < a - c.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"####  Iterated Deletion of Dominated Strategies\\n\",\n    \"\\n\",\n    \"An alternative way to solve this problem is to apply the iterated deletion of dominated strategies. Using the best response function, we can see that the monopoly quantity $\\\\frac{a - c}{2}$ strictly dominates any larger quantity. Hence, removing those dominated quantities, we have\\n\",\n    \"\\n\",\n    \"* $S_1^1 = \\\\left[ 0, \\\\frac{a - c}{2} \\\\right)$ and $S_2^1 = \\\\left[ 0, \\\\frac{a - c}{2} \\\\right)$.\\n\",\n    \"\\n\",\n    \"Given this, we can see the best response function is bounded above by $\\\\frac{a - c}{4}$: $R_i(q_j) \\\\leq \\\\frac{a - c}{4}$. Hence, the quantity $\\\\frac{a - c}{4}$ dominates any lower quantity and removing those dominated quantities, we have\\n\",\n    \"\\n\",\n    \"* $S_1^2 = \\\\left[ \\\\frac{a - c}{4}, \\\\frac{a - c}{2} \\\\right)$ and $S_2^2 = \\\\left[ \\\\frac{a - c}{4}, \\\\frac{a - c}{2} \\\\right)$.\\n\",\n    \"\\n\",\n    \"If we recursively apply this logic, then the strategy set will converge to the Nash equilibrium that is the same as above\\n\",\n    \"\\n\",\n    \"* $S_1^{\\\\infty} = \\\\left \\\\{ \\\\frac{a - c}{3} \\\\right \\\\}$ and $S_2^{\\\\infty} = \\\\left \\\\{ \\\\frac{a - c}{3} \\\\right \\\\}$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Pareto Optimality\\n\",\n    \"\\n\",\n    \"What we have examined so far are all from the perspectives of the players and study how these self-interested agents would make decisions in the face of conflict. Often from a social perspective, we want to examine the game from an outsider's perspective and look at the outcomes (or the payoffs) of the game. As such, we will introduce another form of dominance, namely the *Pareto dominance*.\\n\",\n    \"\\n\",\n    \"###  Pareto Dominance \\n\",\n    \"\\n\",\n    \"When one outcome $o$ is at least as good for every agent as another outcome $o'$, and there is some agent who strictly prefers $o$ to $o'$. Then we say that $o$ **Pareto-dominates** $o'$.\\n\",\n    \"\\n\",\n    \"### Pareto Optimality\\n\",\n    \"\\n\",\n    \"We say an outcome $o^*$ is **Pareto-optimal** if there is no other outcome that Pareto-dominates it.\\n\",\n    \"\\n\",\n    \"We should note that in every game, there should be at least one (and potentially more than one) Pareto-optimal outcome.\\n\",\n    \"\\n\",\n    \"###  Example: Prisoner's Dilemma Revisited\\n\",\n    \"\\n\",\n    \"Let us revisit the Prisoner's Dilemma game:\\n\",\n    \"\\n\",\n    \"| *                       | Prisoner B cooporates | Prisoner B defects    |\\n\",\n    \"|-------------------------|-----------------------|-----------------------|\\n\",\n    \"| Prisoner A cooporates   |       (-1, -1)        |       (-3, 0)         |\\n\",\n    \"| Prisoner A defects      |       (0, -3)         |       (-2, -2)        |\\n\",\n    \"\\n\",\n    \"We can see that the only non-Pareto-optimal outcome is the outcome where both prisoners defect. Interestingly enough, this is also the only Nash equilibrium of the game.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"##  Zero-Sum Game\\n\",\n    \"\\n\",\n    \"###  Introduction\\n\",\n    \"\\n\",\n    \"A zero-sum game refers to a game where in each situation, each player's gain or loss of utility is exactly balanced by the losses or gains of the utility of the other players. If the total gains of all agents are added up and the total losses are subtracted, they will sum to zero and thus the name zero-sum game. \\n\",\n    \"\\n\",\n    \"Less formally, it is a game where a player cannot make herself better off without making another player worse off. A simple example of two-player zero-sum game is the tennis match, where if one player wins, the other player must lose. Another example introduced earlier in our notes is the matching pennies example, which we will see next.\\n\",\n    \"\\n\",\n    \"A counter-example or an example for a non-zero-sum game is the game of chess, where if the game ends up in a draw, then both players will split the point.\\n\",\n    \"\\n\",\n    \"### Example: Matching Pennies\\n\",\n    \"\\n\",\n    \"Matching pennies is an example of zero-sum game. If for example two heads were observed, then the row player will win and receive one extra penny at the cost of the other player losing his penny. One can easily check the zero-sum condition is satisfied by all scenarios.\\n\",\n    \"\\n\",\n    \"| *           | H       | T       |\\n\",\n    \"|-------------|---------|---------|\\n\",\n    \"| H           | (1, -1) | (-1, 1) |\\n\",\n    \"| T           | (-1, 1) | (1, -1) |\\n\",\n    \"\\n\",\n    \"###  Relationship to Pareto Optimality\\n\",\n    \"\\n\",\n    \"Zero-sum games have an interesting property that all outcomes are Pareto optimal. This is rather intuitive as if one outcome Pareto-dominates another, then it must be the case where one of them is non-zero-sum. \\n\",\n    \"\\n\",\n    \"The idea of Pareto optimal payoff in a zero-sum game gives rise to a relatively selfish rationality standard, the so-called *punishing-the-opponent* standard, where by minimising opponents' payoff at a favourable cost to himself, one can maximise his own payoff. As such, this leads to the maxmin and minmax strategies.\\n\",\n    \"\\n\",\n    \"There is a nice interactive game, called the [evolution of trust](https://ncase.me/trust/) by Nicky Case, that shows the importance of non-zero-sum games for trusts to evolve in our society.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Maxmin Strategy\\n\",\n    \"\\n\",\n    \"### Definition: Maxmin\\n\",\n    \"\\n\",\n    \"Player $i$'s **maxmin strategy** is a strategy that maximises $i$'s worst-case payoff, in the situation where all other players (whom we denote $-i$) happen to play the strategies which cause the greatest harm to $i$. More formally, the maxmin strategy is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\arg \\\\max_{s_i \\\\in S_i} \\\\min_{s_{-i} \\\\in S_{-i}} u_i ( s_i, s_{-i} ).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"An agent $i$ might play the maxmin strategy if $i$ is very conservative or paranoid.\\n\",\n    \"\\n\",\n    \"###  Definition: Minmax\\n\",\n    \"\\n\",\n    \"Player $i$'s **minmax strategy** is a strategy that minimises $i$'s worst-case loss (i.e. maximum loss). Minmax strategy originated from zero-sum game, where it actually minimises all other players' (once again, we denote $-i$) maximal gain (which is the same as $i$'s maximum loss by the zero-sum principle). That is, the minmax strategy is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\arg \\\\min_{s_i \\\\in S_i} \\\\max_{s_{-i} \\\\in S_{-i}} u_{-i} ( s_i, s_{-i} ).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"An agent $i$ might play the minmax strategy to punish other agents as much as possible. For zero-sum game in particular, this strategy is equivalent to maximise one's own payoff. \\n\",\n    \"\\n\",\n    \"###  Minimax Theorem (von Neumann)\\n\",\n    \"\\n\",\n    \"> In any finite, two-player zero-sum game and in any Nash equilibrium, each player receives a payoff that is equal to both his maxmin value and his minmax value.\\n\",\n    \"\\n\",\n    \"Maxmin value and minmax value are the payoffs for the player who deployed the maxmin strategy and minmax strategy respectively. Hence informally, this theorem implies that the maxmin srategy, minmax strategy and Nash equilibrium concept all give rise to the same solutions in a zero-sum game. As such, we can see why the (socially) undesirable *punishing-the-opponent* standard (from **1.11.3**) would arise in zero-sum game.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"##  Correlated Equilibrium\\n\",\n    \"\\n\",\n    \"###  Intuition and Traffic Game\\n\",\n    \"\\n\",\n    \"We will briefly go through the intuition behind another game theoretic solution concept other than Nash equilibrium. Consider the example of traffic game between two drivers (players) at an intersection with the following payoff.\\n\",\n    \"\\n\",\n    \"|   *  |    go    |  wait  |\\n\",\n    \"|------|----------|--------|\\n\",\n    \"|  go  | -10, -10 |  1, 0  |\\n\",\n    \"| wait |   0,  1  | -1, -1 |\\n\",\n    \"\\n\",\n    \"Both drivers would prefer to pass the intersection as quickly as possible, but if both drivers decide to go, then this will be the worse case scenario where both cars crush into each other. On the other hand, if both drivers decide to wait, then they would still be in the intersection waiting for the other driver to go. Hence the desirable outcome (or the Pareto optimal outcome) is for one car to quickly pass through the intersection while the other car waits behind the line. However, under the game theoretic assumption, it appears difficult to coordinate the drivers to reach the desriable outcome.\\n\",\n    \"\\n\",\n    \"There are three Nash equilibriums in this game, namely the two symmetric pure strategy equilibrias\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\{ (\\\\text{go}, \\\\text{wait}), (\\\\text{wait}, \\\\text{go}) \\\\},\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"and some mixed strategy equilibrium. However, if both drivers choose a mixed strategy, then there is a positive possibility that both car will go ahead and crush into each other. \\n\",\n    \"\\n\",\n    \"The natural solution that we use is through a traffic light control, which is a *fair randomising device* that tells one of the agents to go and the other to wait. In this case, we can both avoid the undesirable negative payoff situations, and possibly achieve a Pareto optimal outcome. Hence, we arrive at the notion of correlated equilibrium.\\n\",\n    \"\\n\",\n    \"###  Informal Definition\\n\",\n    \"\\n\",\n    \"Informally, a correlated equilibrium is a randomised assignment of (potentially correlated) action recommendations to agents, such that no agent wants to deviate.\\n\",\n    \"\\n\",\n    \"###  A More Formal Definition\\n\",\n    \"\\n\",\n    \"More formally, if we define *strategy modification* for player $i$ as a function $\\\\phi_i: A_i \\\\rightarrow A_i$, which tells player $i$ to modify her behaviour by playing action $\\\\phi_i(a_i)$ when she was instructed to play $a_i$. Moreover, define $\\\\Omega$ to be the sample space of all possible situations in the game, and $q_i(\\\\omega)$ be $i$'s posterior belief (probability) of $\\\\omega$ to occur. Then a correlated equilibrium consists of a set of strategy profiles (or instructions) $s = (s_1, \\\\ldots, s_n)$, one for each player, such that no player can improve his or her expected utility via a strategy modification.\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\sum_{\\\\omega \\\\in \\\\Omega} q_i(\\\\omega) u_i (s_i (\\\\omega), s_{-i} (\\\\omega) \\\\geq \\\\sum_{\\\\omega \\\\in \\\\Omega} q_i(\\\\omega) u_i (\\\\phi_i(s_i (\\\\omega)), \\\\phi_i(s_{-i} (\\\\omega)) \\\\hspace{5mm} \\\\forall \\\\phi_i \\\\in \\\\Phi_i, \\\\hspace{2mm} i = 1, \\\\ldots, n,\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"where $\\\\Phi_i$ is the class of all strategy modifications for player $i$.\\n\",\n    \"\\n\",\n    \"The notion of posterior belief $q_i(\\\\cdot)$ arises in an extensive form game (where players move sequentially rather than simultanously) with imperfect information. We will talk more about this in the Bayesian game.\\n\",\n    \"\\n\",\n    \"### Relation to Nash Equilibrium\\n\",\n    \"\\n\",\n    \"It should be noted that correlated equilibrium generalises Nash equilibrium. That is, every mixed Nash equilibrium is a correlated equilibrium. If the action-recommendations in a correlated equilibrium are not correlated at all, then we have the Nash equilibrium.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Extensive Form Game\\n\",\n    \"\\n\",\n    \"In normal form game, players take action simultanously, whereas in extensive form game, players take action **sequentially**. As such, players can make decision based on his or her observations of what the previous decision makers choose. However, the full history of decisions may not be accessible to some players so that they have to decide based on the information they know. To formally formulate this, we will introduce the formal definition of a finite extensive form game.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"##  Formal Definition\\n\",\n    \"\\n\",\n    \"###  The Game\\n\",\n    \"\\n\",\n    \"Formally, a finite extensive form game consists of \\n\",\n    \"\\n\",\n    \"* A finite set of players $\\\\mathcal{I} = \\\\{1, \\\\ldots, I\\\\}$.\\n\",\n    \"\\n\",\n    \"* A finite set of nodes $X$ that forms a tree, with $Z \\\\subset X$ being the terminal nodes.\\n\",\n    \"\\n\",\n    \"* A set of functions that describe for each $x \\\\notin Z$,\\n\",\n    \"    * the player $i(x)$ who moves at $x$;\\n\",\n    \"    * the set $A(x)$ of possible actions at $x$;\\n\",\n    \"    * the successor node $n(x, a)$ resulting from action $a \\\\in A(x)$.\\n\",\n    \"    \\n\",\n    \"* Payoff function $u_i: Z \\\\rightarrow \\\\mathbb{R}$ that assigns payoffs to players as a function of the terminal node reached.\\n\",\n    \"\\n\",\n    \"* An information partition: for each $x$, let $h(x)$ denote the set of nodes that are possible given what $i(x)$ knows.\\n\",\n    \"\\n\",\n    \"We introduce a few more notations.\\n\",\n    \"\\n\",\n    \"* The set $H_i$ of information sets at which player $i$ moves.\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  H_i = \\\\{ S \\\\subset X \\\\hspace{2mm}: \\\\hspace{2mm} S = h(x) \\\\hspace{2mm} \\\\text{for some} \\\\hspace{2mm} x \\\\in X \\\\hspace{2mm} \\\\text{with} \\\\hspace{2mm} i(x) = i \\\\}.  \\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"* The set $A_i$ of actions avaliable to $i$ at any of his or her information sets.\\n\",\n    \"\\n\",\n    \"We will use $i(h)$ and $A(h)$ to denote the player who moves at information set $h$ and his or her set of possible actions respectively.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Pure Strategy\\n\",\n    \"\\n\",\n    \"In an extensive form game, a player's pure strategy is a plan of action for the entire game, that tells the player what choice to take at every conjucture of the game where he or she has to move. More formally,\\n\",\n    \"\\n\",\n    \"> A pure strategy for player $i$ is a function $s_i: H_i \\\\rightarrow A_i$ such that $s_i(h) \\\\in A(h)$ for each $h \\\\in H_i$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Mixed Strategy\\n\",\n    \"\\n\",\n    \"> A mixed strategy for player $i$ is a probability distribution $\\\\sigma_i \\\\in \\\\Delta (S_i)$ over pure strategies.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Support\\n\",\n    \"\\n\",\n    \"Given a mixed strategy $\\\\sigma_i$, we say a pure strategy $s_i \\\\in S_i$ is in the *support* of $\\\\sigma_i$ if and only if $\\\\sigma_i(s_i) > 0$. \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Behaviour Strategy\\n\",\n    \"\\n\",\n    \"A player's behaviour strategy at a decision node where the player has to move is a probability distribution over the choices avaliable at the decision node. More formally,\\n\",\n    \"\\n\",\n    \"> A behaviour strategy for player $i$ is a function $\\\\sigma_i: H_i \\\\rightarrow \\\\Delta(A_i)$ such that $\\\\text{support}(\\\\sigma_i(h)) \\\\subset A(h)$ for all $h \\\\in H_i$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Perfect Information\\n\",\n    \"\\n\",\n    \"A game of perfect information is a game where each player is perfectly informed of all the events that have previously occured when making any decision, including the initialisation event of the game. Under perfect information, each information set has only one element, namely the point actually reached at the stage of the game.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"##  The Normal Form Representation and Nash Equilibrium\\n\",\n    \"\\n\",\n    \"Once we know what the set of pure strategies is for each player, we can write down the normal form representation of an extensive form game and solve for Nash equilibrium. The Nash equilibrium of an extensive form game is the Nash equilibrium of its normal form representation.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {\n    \"heading_collapsed\": true\n   },\n   \"source\": [\n    \"## Kuhn's Theorem\\n\",\n    \"\\n\",\n    \"### Perfect Recall\\n\",\n    \"\\n\",\n    \"We define games of perfect recall as games where\\n\",\n    \"\\n\",\n    \"* players never forgets a decision he or she took in the past,\\n\",\n    \"* players never forgets information he or she had when making a decision.\\n\",\n    \"\\n\",\n    \"###  Kuhn's Theorem\\n\",\n    \"\\n\",\n    \"Kuhn's theorem says that in games of perfect recall, mixed and behaviour strategy are equivalent in the sense that for any mixed strategy there is an equivalent behavioural strategy and vice versa.\\n\",\n    \"\\n\",\n    \"Since essentially all the games we will consider in this section have perfect recall, we will use mixed and behaviour strategy interchangeably.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Stackleberg Competition\\n\",\n    \"\\n\",\n    \"An alternative model to the Cournot model of duopoly (**1.9.1**) is the Stackleberg Competition where it assumes one firm is the market *leader*, while the other firm (or firms) are *followers*. In Stackleberg model, Firm 1 will act first to set a quantity $q_1$, and Firm 2 will act second to set a quantity $q_2$, after observing Firm 1's action $q_1$. The price is then determined by $P(Q) = a - Q$, where $Q = q_1 + q_2$. Moreover, assume that both firms have constant marginal cost that equals to $0 \\\\leq c \\\\leq a$, this allows us to make comparison with the Cournot model.\\n\",\n    \"\\n\",\n    \"In this model, we claim that for any $q'_1 \\\\in [c, a]$, there is a Nash equilibrium in which Firm 1 or the market *leader* chooses quantity $q'_1$. To see this, consider Firm 1's strategy profile\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  s_1 = q'_1,\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"and Firm 2's strategy profile\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  s_2 = \\\\begin{cases}\\n\",\n    \"          \\\\frac{a - q'_1 - c}{2} & \\\\text{ if $q_1 = q'_1$},\\\\\\\\\\n\",\n    \"          a - q'_1 - c & \\\\text{ if $q_1 \\\\neq q'_1$}.\\n\",\n    \"        \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Now given Firm 2's strategy, Firm 1 can either set $q_1 = q'_1$ or $q_1 \\\\neq q'_1$. We can see that the first quantity leads to positive payoff while the second option leads to zero price $P(Q) = 0$ and hence zero profit. Hence Firm 1's best response against Firm 2's strategy $s_2$ is $s_1$. \\n\",\n    \"\\n\",\n    \"Given Firm 1's strategy, Firm 2's best response is the strategy \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\arg \\\\max_{q_2} q_2 (a - q'_1 - q_2 - c)\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"which equals to $\\\\frac{a - q'_1 - c}{2}$ following the same working out as **1.9.1.3**. Hence Firm 2's best response against Firm'1 strategy $s_1$ is $s_2$. Then by definition, $(s_1, s_2)$ is a Nash equilibria. \\n\",\n    \"\\n\",\n    \"However, many of the Nash euqilibria in the Stackelberg model seems unreasonable. If Firm 1 sets $q_1 \\\\neq q'_1$, then Firm 2 can choose an quantity that ensures a positive payoff instead of flooding the market to drive the price to zero. Hence, Firm 2 is making an [incredible threat](https://en.wikipedia.org/wiki/Non-credible_threat) that a rational player would not actually carry out. One way to eliminate these non-credible threats is through the notion of *subgame perfect equilibrium* and *backward induction*.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"##  Subgame Perfect Equilibrium and Backward Induction\\n\",\n    \"\\n\",\n    \"In this section, we will first formalise the notion of subgame perfect equilibrium and backward induction. Then, we will apply them to find the subgame perfect equilibrium of the Stackleberg problem introduced in the last section.\\n\",\n    \"\\n\",\n    \"Subgame perfect equilibrium tried to rule out incredible threats by assuming once something has happened, players will always optimise going forward.\\n\",\n    \"\\n\",\n    \"###  Subgame\\n\",\n    \"\\n\",\n    \"Let $G$ be an extensive form game, a subgame $G'$ of $G$ consists of\\n\",\n    \"\\n\",\n    \"* a subset $Y \\\\subset X$ of nodes consisting of a single non-terminal node $x \\\\in X$ and all of its successors, which has the property if $y \\\\in Y$ and $y' \\\\in h(y)$, then $y' \\\\in Y$;\\n\",\n    \"* information sets, feasible moves, and payoffs at terminal nodes as in $G$.\\n\",\n    \"\\n\",\n    \"###  Subgame Perfect Equilibrium\\n\",\n    \"\\n\",\n    \"A strategy profile $s$ is a *subgame perfect equilibrium* of $G$ if it induces a Nash equilibrium in every subgame of $G$.\\n\",\n    \"\\n\",\n    \"### Backward Induction\\n\",\n    \"\\n\",\n    \"To identify subgame perfect equilibrium, one common approach is to start at the end of the game or the terminal branches, and work back to the top of the tree. The general procedure is shown below.\\n\",\n    \"\\n\",\n    \"* First, resolve the *last* subgame in the game.\\n\",\n    \"* Then, substitute the subgame by expected payoff induced by the Nash equilibria of the subgame.\\n\",\n    \"* Keep resolving the new *last* subgame in the same way until we solve the entire game.\\n\",\n    \"\\n\",\n    \"We will illustrate this technique in solving the Stackleberg competition.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"###  Stackleberg Competition Continued \\n\",\n    \"\\n\",\n    \"Since Firm 2 makes its move last, under backward induction, we will determine its best response first. From **2.5** we know if Firm 1 produces $q_1$ quantity of goods, then Firm 2's best response is to produce \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  q^*_2 \\\\hspace{1mm} (q_1) = \\\\frac{a - q_1 - c}{2}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Hence, knowing Firm 2's best response, Firm 1 will produce $q_1$ that equals to\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\arg \\\\max_{q_1} q_1 (a - q_1 - q^*_2 \\\\hspace{1mm} (q_1) - c) = \\\\arg \\\\max_{q_1} q_1 \\\\left( a - q_1 - \\\\frac{a - q_1 - c}{2} - c\\\\right).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Solving this yields\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  q_1 = \\\\frac{a - c}{2} \\\\hspace{7mm} \\\\text{and} \\\\hspace{7mm} q_2 = \\\\frac{a - c}{4}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Which is different from the equilibrium in the Cournot model of duoploy:\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  q_1^C = q_2^C = \\\\frac{a - c}{3}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Hence this game has a first-mover advantage, in the sense that there is an advantage to being the leader.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### Criticisms of Subgame Perfection\\n\",\n    \"\\n\",\n    \"We use Subgame Perfection Equilibrium (SPE) as a mean to remove incredible threats. However, SPE might be over-ambitious in removing these threats. In a game with many stages, backward induction greatly stresses the assumption of rationality and common knowledge of rationality. Many experiments (e.g. [Goeree and Holt 2001](https://www.stat.berkeley.edu/~aldous/157/Papers/goeree.pdf)) have shown that the player that moves first often deviates from the SPE simply because they do not trust the second player to be rational.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# 3. Static Game of Incomplete Information\\n\",\n    \"\\n\",\n    \"We see that SPE can be used to solve extensive form game with perfect information. In this section we will deal with extensive form games with imperfect information.\\n\",\n    \"\\n\",\n    \"## 3.1 Introduction\\n\",\n    \"\\n\",\n    \"Informally, a *Bayesian game* or a game of *incomplete information* is a game where the players do not have common knowledge of the game being played. A *static* or simultanous move game is a game where at each stage, players move at the same time without any knowledge of the others' decisions. \\n\",\n    \"\\n\",\n    \"### 3.1.1 Types\\n\",\n    \"\\n\",\n    \"Moreover, we consider a set of *types* for each player, which represent all possible different information they can privately know that affects payoffs. Hence, the payoff now would depend on both the action and the types (potentially on the types of all players). We also assume the prior probability distribution of types\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  T_i \\\\sim p_i (t_i), \\\\hspace{5mm} i = 1, \\\\ldots, n.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"is a common knowledge.\\n\",\n    \"\\n\",\n    \"### 3.1.2 Beliefs\\n\",\n    \"\\n\",\n    \"In general, we also need to specify beliefs that the players have. A belief is a probability distribution over all the nodes in an information set. More formally, given a prior, a (posterior) belief in a static game is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  p_i \\\\left( t_{-i} \\\\vert t_i \\\\right) = \\\\frac{p \\\\left(t_i \\\\vert t_{-i} \\\\right) p \\\\left( t_{-i} \\\\right)}{\\\\int_{T_{-i}} p \\\\left( t_i \\\\vert z \\\\right)p(z)dz}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"If types are independent, then $p_i \\\\left( t_{-i} \\\\vert t_i \\\\right)  = p \\\\left( t_{-i} \\\\right)$, that is, the posterior beliefs and the prior beliefs are the same.\\n\",\n    \"\\n\",\n    \"More generally, in an extensive form game (with imperfect information and multiple information partitions), the agent usually update their beliefs (via the Bayes rule on the prior beliefs) when they receive more information.\\n\",\n    \"\\n\",\n    \"### 3.1.3 Robber's Example\\n\",\n    \"\\n\",\n    \"Suppose there is a robber with a gun asking for you wallet. The robber can either be a good robber where he needs the money but would prefer not harming you, or a bad robber where he would not mind killing you. Robber's type (good or bad) is his private information that is unkown to you (imperfect information), but both you and the robber have access to the public information about the overall distribution of good/bad robbers (i.e. the prior distribution of robber's type). \\n\",\n    \"\\n\",\n    \"Based on your own type (your private information that is unkown to the robber), you will have your *belief* about the type of robber you are facing and simultanously, the robber would also have his belief about what type of person you are. Hence, what you and the robber get out of this situation (your payoffs) depend both on your actions (e.g. give the wallet or not) and your types.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 3.2 Normal Form Representation Of Static Bayesian Game\\n\",\n    \"\\n\",\n    \"More formally, a normal form representation of an $n$-player game of incomplete information consists of\\n\",\n    \"\\n\",\n    \"* an action space $A \\\\equiv A_1 \\\\times \\\\ldots \\\\times A_n$;\\n\",\n    \"* a type space $T \\\\equiv T_1 \\\\times \\\\ldots \\\\times T_n$;\\n\",\n    \"* payoff functions $u \\\\equiv u_1, \\\\ldots, u_n$ defined over $A \\\\times T$ with $u_i(a \\\\vert t), a \\\\in A$ and $t \\\\in T$;\\n\",\n    \"* beliefs $p \\\\equiv p_1, \\\\ldots, p_n$.\\n\",\n    \"\\n\",\n    \"Moreover, we denote the game by $G = (A, T, p, u)$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 3.3 Bayesian Strategy\\n\",\n    \"\\n\",\n    \"In the static Bayesian game $G = (A, T, p, u)$, we define Bayesian strategy for player $i$ as a function $s_i (t_i)$ which, for each type $t_i \\\\in T_i$, specifies the action from the feasible set $A_i$ that type $t_i$ would choose if drawn from Nature.\\n\",\n    \"\\n\",\n    \"That is, we reduce the extensive form and define different strategies for each different player-type $t_i$. Said otherwise, each player-type is treated as a different player.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 3.4 Bayes Nash Equilibrium\\n\",\n    \"\\n\",\n    \"In the static Bayesian game $G = (A, T, p, u)$, the strategy profile $s^* = \\\\left( s^*_1, \\\\ldots, s^*_n \\\\right)$ is a (pure strategy) Bayes Nash equilibrium if for each player $i$ and each of $i$'s types $t_i \\\\in T_i$,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  s^*_i (t_i) \\\\in \\\\arg \\\\max_{s_i \\\\in S_i} \\\\mathbb{E} [ u_i \\\\left( a_i, s_{-i} \\\\left( t_{-i} \\\\right) \\\\vert t \\\\right) \\\\vert t_i], \\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"where\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\mathbb{E} [ u_i \\\\left( a_i, s_{-i} \\\\left( t_{-i} \\\\right) \\\\vert t \\\\right) \\\\vert t_i] = \\\\sum_{t_{-i} \\\\in T_{-i}} u_i \\\\left( a_i, s_{-i} \\\\left( t_{-i} \\\\right) \\\\vert t \\\\right) p_i (t_{-i} \\\\vert t_i).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"That is, each player-type is maximising the expected payoff conditional on her own type.\\n\",\n    \"\\n\",\n    \"We can easily extend this definition to mixed strategies and infinite games.\\n\",\n    \"\\n\",\n    \"With arguments very similar to Nash equilibrium, a Bayes Nash equilibrium always exists for finite games.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 3.5 Application: Auction\\n\",\n    \"\\n\",\n    \"### 3.5.1 Problem Setting\\n\",\n    \"\\n\",\n    \"To see an example of the application of Bayesian games, consider a [first-place sealed-bid auction](https://en.wikipedia.org/wiki/First-price_sealed-bid_auction) between two bidders $i = 1, 2$, each with valuation of $v_i \\\\sim \\\\mathcal{U}(0, 1)$ drawn from nature. Moreover, assume\\n\",\n    \"\\n\",\n    \"* actions: $b_i \\\\in [0, \\\\infty)$;\\n\",\n    \"* types: $T_i = [0, 1]$;\\n\",\n    \"* beliefs: $p_i (v_i \\\\vert v_j) = p_i (v_i)$ if $i \\\\neq j$;\\n\",\n    \"* tie-breaking rule is via tossing a fair coin.\\n\",\n    \"\\n\",\n    \"Then, the payoff function for each bidder is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i (b_i, b_j \\\\vert v_i) = \\\\begin{cases}\\n\",\n    \"          v_i - b_i & \\\\text{ if } b_i > b_j;\\\\\\\\\\n\",\n    \"          \\\\frac{1}{2}(v_i - b_i) & \\\\text{ if } b_i = b_j;\\\\\\\\\\n\",\n    \"          0 & \\\\text{ if } b_i < b_j.\\n\",\n    \"        \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"### 3.5.2 Bayes Equilibrium\\n\",\n    \"\\n\",\n    \"If we write $b_i (v_i)$ as the Bayes strategy where player $i$ would bid $b_i$ if its valuation is $v_i$, then player $i$ should try to bid $b_i$ that maximise her expected payoff\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\mathbb{E} [u_i (b_i(v_i), b_j(v_j)) \\\\vert v_i] = (v_i - b_i) \\\\mathbb{P} (b_i > b_j (v_j)) + \\\\frac{1}{2}(v_i - b_i) \\\\mathbb{P} (b_i = b_j (v_j)).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Now, let us make a simplifying assumption that players can only use linear strategies, that is, $b_j (v_j) = \\\\alpha + \\\\beta v_j$, for $j = 1, 2$. Then, player $i$ should choose $b^*_i$ such that \\n\",\n    \"\\n\",\n    \"\\\\begin{align*}\\n\",\n    \"  b^*_i &= \\\\arg \\\\max_{b_i} (v_i - b_i) \\\\mathbb{P} (b_i > \\\\alpha + \\\\beta v_j)\\\\\\\\\\n\",\n    \"        &= \\\\arg \\\\max_{b_i} (v_i - b_i) \\\\mathbb{P} \\\\left( v_j < \\\\frac{b_i - \\\\alpha}{\\\\beta} \\\\right)\\\\\\\\\\n\",\n    \"        &= \\\\arg \\\\max_{b_i} \\\\frac{(v_i - b_i)(b_i - \\\\alpha)}{\\\\beta}\\\\\\\\\\n\",\n    \"        &= \\\\frac{v_i + \\\\alpha}{2}.\\n\",\n    \"\\\\end{align*}\\n\",\n    \"\\n\",\n    \"Note that we used the fact that $v_j \\\\sim \\\\mathcal{U}(0, 1)$ is continous, so $\\\\mathbb{P} (v_j = c) = 0$ for any constant $c$. \\n\",\n    \"\\n\",\n    \"To find $\\\\alpha$, we should note that no bidder would bid higher than its valuation, i.e. $b_i(v_i) \\\\leq v_i$. Setting $v_i$ to 0 we must then have  $b^*_i(0) = \\\\frac{\\\\alpha}{2} \\\\leq 0$, so $\\\\alpha = 0$. \\n\",\n    \"\\n\",\n    \"Hence, we have a Bayes-Nash equilibrium where bidders bid half of their valuation.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 3.6 Purification Theorem\\n\",\n    \"\\n\",\n    \"Harsanyi (1973) proposed the purification theorem in an attempt to justify some puzzling aspect of mixed strategy equilibria (as mentioned in **1.7.4.2**): \\n\",\n    \"\\n\",\n    \"> each player is wholly indifferent amongst each of the actions in support of his mixed strategy, yet he mixes them so as to make every other player also indifferent.\\n\",\n    \"\\n\",\n    \"It also provides an intuitive answer to the critic that players do not seem to randomise in practice.\\n\",\n    \"\\n\",\n    \"### 3.6.1 Motivating Example\\n\",\n    \"\\n\",\n    \"Consider the coordination game between two players with the following normal form representation:\\n\",\n    \"\\n\",\n    \"| * |   L  |   R  | \\n\",\n    \"|---|------|------|\\n\",\n    \"| L | 2, 2 | 0, 0 |\\n\",\n    \"| R | 0, 0 | 1, 1 |\\n\",\n    \"\\n\",\n    \"One can easily compute the (mixed) Nash equilibrium\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\left\\\\{ (L, L), \\\\left( \\\\frac{1}{3}L + \\\\frac{2}{3}R, \\\\frac{1}{3}L + \\\\frac{2}{3}R \\\\right), (R, R) \\\\right\\\\}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Now, suppose we slightly perturb the payoff of the game by introducing a payoff shock\\n\",\n    \"\\n\",\n    \"| * |   L  |   R  | \\n\",\n    \"|---|------|------|\\n\",\n    \"| L | 2 + $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1L}$, 2 + $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{2L}$| $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1L}$, $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{2R}$ |\\n\",\n    \"| R | $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1R}$, $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{2L}$ | 1 + $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1R}$, 1 + $\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{2R}$ |\\n\",\n    \"\\n\",\n    \"where $\\\\epsilon > 0$ is the commonly known parameter describing the size of the shock, and $\\\\left( \\\\eta_{1L}, \\\\eta_{1R} \\\\right)$ and $\\\\left( \\\\eta_{2L}, \\\\eta_{2R} \\\\right)$ are independent  stochastic shock that are player $i$'s private information. Finally, assume $\\\\eta_i = \\\\eta_{iL} - \\\\eta_{iR} \\\\sim F$ for some continuous cumulative distribution function $F$ on the real line. \\n\",\n    \"\\n\",\n    \"Then, each player's equilibrium strategy will follow a threshold strategy of the form\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  s_i (\\\\eta_i) = \\\\begin{cases}\\n\",\n    \"                     L & \\\\text{ if } \\\\eta_i \\\\leq z_i := F^{-1} (\\\\pi_i);\\\\\\\\\\n\",\n    \"                     R & \\\\text{ if } \\\\eta_i > z_i := F^{-1} (\\\\pi_i),\\n\",\n    \"                 \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"where $\\\\pi_i$ is player $i$'s equilibrium probability of playing $L$. Then we know from **1.7.4** that if player $i$ mixes between $L$ and $R$ (as her equilibrium strategy), then she must be indifferent between $L$ and $R$. That is, $\\\\eta_1 = F^{-1} (\\\\pi_1)$ and $1$'s expected payoff when playing $L$ and $R$ \\n\",\n    \"\\n\",\n    \"\\\\begin{align*}\\n\",\n    \"  \\\\mathbb{E} u_1 (L, s_2) &= \\\\pi_2 (2 + \\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1L}) + (1 - \\\\pi_2) \\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1L};\\\\\\\\\\n\",\n    \"  \\\\mathbb{E} u_1 (R, s_2) &= \\\\pi_2 \\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1R} + (1 - \\\\pi_2) (1 + \\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1R});\\n\",\n    \"\\\\end{align*}\\n\",\n    \"\\n\",\n    \"must be equal. Thus, we have\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\mathbb{E} u_1 (L, s_2) - \\\\mathbb{E} u_1 (R, s_2) = \\\\pi_2 (2 + \\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1}) + (1 - \\\\pi_2)(\\\\epsilon \\\\hspace{0.5mm} \\\\eta_{1} - 1) = 0,\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"that is,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\frac{1 - 3 \\\\pi_2}{\\\\epsilon} = \\\\eta_1 = F^{-1} (\\\\pi_1).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Since the game is symmetric, we must have $\\\\pi_1 = \\\\pi_2 = \\\\pi$ and hence \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  1 - 3 \\\\pi = \\\\epsilon F^{-1} (\\\\pi).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"This equation has solutions $pi$ tending $0, \\\\frac{1}{3}, 1$, which are precisely the mixed Nash equilibrium probability for the original game. \\n\",\n    \"\\n\",\n    \"Hence, we can think of mixed strategy equilibrium as the outcome of pure strategy followed by players who have a small amount of private information about their payoffs.\\n\",\n    \"\\n\",\n    \"We shall formalise this as follows.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 3.6.2 Payoff Pertubation\\n\",\n    \"\\n\",\n    \"Consider an $I$-player complete information game $G(A, u)$ where $A = A_1 \\\\times \\\\ldots \\\\times A_I$ is the action space and $u_i: A \\\\rightarrow \\\\mathbb{R}$ is the utility functions for player $i$, $i = 1, \\\\ldots, I$. \\n\",\n    \"\\n\",\n    \"The payoff-perturbed game is then an incomplete information game where each player privately observe $\\\\eta_i \\\\in \\\\mathbb{R}^{\\\\vert A \\\\vert}$ and his payoff when action profile $a \\\\in A$ is chosen is then $u_i(a) + \\\\eta_{ia}$. Then any pure strategy profile $s$ in this game induces a probability distribution over actions $\\\\nu_s \\\\in \\\\Delta(A)$ such that\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\nu_s (a) = \\\\mathbb{P}_\\\\mu \\\\{\\\\nu : s_i(\\\\eta_i) = a_i \\\\text{ for each } i\\\\}.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 3.6.3 Purification Theorem\\n\",\n    \"\\n\",\n    \"Suppose $\\\\alpha \\\\in \\\\Delta(A_1) \\\\times \\\\ldots \\\\Delta(A_I)$ is a Nash equilibrium of the complete information game $G$, then for all $\\\\epsilon > 0$ and $a \\\\in A$, \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\left\\\\vert \\\\nu_s (a) - \\\\prod_{i = 1}^I \\\\alpha_i (a_i) \\\\right\\\\vert \\\\leq \\\\epsilon.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"An elegant proof of a more generalised theorem of this can be found in Govindan, Reny and Robson (2003).\\n\",\n    \"\\n\",\n    \"### 3.6.4 Comments\\n\",\n    \"\\n\",\n    \"Purification theorem shows that all equilibria (pure or mixed) of almost all complete information game are the limit of pure strategy equilibria of perturbed games where players have independent small shocks (that is only known to themselves) to the payoffs.\\n\",\n    \"\\n\",\n    \"More intuitively, suppose a player has some private information or inclination to choose an action over another, but this information is not known to other players. Then this player's observed behaviour will look, from the perspectives of other players, as if he is randomising between his actions, even though he may not experience the choice as randomisation.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# 4. Dynamic Games of Incomplete Information\\n\",\n    \"\\n\",\n    \"In extensive form game with incomplete information, subgame perfection does not work so well. In particular, some games (with incomplete information) can have no subgame at all and hence we would collect all Nash equilibrium of the game, including those that are unreasonable.\\n\",\n    \"\\n\",\n    \"Hence, we would like to define a new equilibrium concept to resolve these problems. But before doing that, we need to recap our notations and definitions.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.1 Definition Recap\\n\",\n    \"\\n\",\n    \"We shall quickly recap on the definition of the game given in **2.1.1**.\\n\",\n    \"\\n\",\n    \"* A finite set of players $\\\\mathcal{I} = \\\\{1, \\\\ldots, I\\\\}$.\\n\",\n    \"\\n\",\n    \"* A finite set of nodes $X$ that forms a tree, with $Z \\\\subset X$ being the terminal nodes.\\n\",\n    \"\\n\",\n    \"* A set of functions that describe for each $x \\\\notin Z$,\\n\",\n    \"    * the player $i(x)$ who moves at $x$;\\n\",\n    \"    * the set $A(x)$ of possible actions at $x$;\\n\",\n    \"    * the successor node $n(x, a)$ resulting from action $a \\\\in A(x)$.\\n\",\n    \"    \\n\",\n    \"* Payoff function $u_i: Z \\\\rightarrow \\\\mathbb{R}$ that assigns payoffs to players as a function of the terminal node reached.\\n\",\n    \"\\n\",\n    \"* An information partition: for each $x$, let $h(x)$ denote the set of nodes that are possible given what $i(x)$ knows.\\n\",\n    \"\\n\",\n    \"* The set $H_i$ of information sets at which player $i$ moves.\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  H_i = \\\\{ S \\\\subset X \\\\hspace{2mm}: \\\\hspace{2mm} S = h(x) \\\\hspace{2mm} \\\\text{for some} \\\\hspace{2mm} x \\\\in X \\\\hspace{2mm} \\\\text{with} \\\\hspace{2mm} i(x) = i \\\\}.  \\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"* The set $A_i$ of actions avaliable to $i$ at any of his or her information sets.\\n\",\n    \"\\n\",\n    \"We will use $i(h)$ and $A(h)$ to denote the player who moves at information set $h$ and his or her set of possible actions respectively.\\n\",\n    \"\\n\",\n    \"### 4.1.1 Behaviour Strategy\\n\",\n    \"\\n\",\n    \"A player's behaviour strategy at a decision node where the player has to move is a probability distribution over the choices avaliable at the decision node. More formally,\\n\",\n    \"\\n\",\n    \"> A behaviour strategy for player $i$ is a function $\\\\sigma_i: H_i \\\\rightarrow \\\\Delta(A_i)$ such that $\\\\text{support}(\\\\sigma_i(h)) \\\\subset A(h)$ for all $h \\\\in H_i$.\\n\",\n    \"\\n\",\n    \"### 4.1.2 Belief\\n\",\n    \"\\n\",\n    \"The belief $\\\\mu_i ( x \\\\vert h_i)$ of agent $i$ at a given information set $h_i \\\\in H_i$ is a probability distribution over the nodes $x \\\\in h_i$ in the information set. Write $\\\\mu_i$ as player $i$'s belief over her entire information set $H_i$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.2 Assessment\\n\",\n    \"\\n\",\n    \"An assessment $(\\\\sigma_i, \\\\mu_i)$ for player $i$ is a tuple of player $i$'s behaviour strategy $\\\\sigma_i$ and beliefs $\\\\mu_i$. \\n\",\n    \"\\n\",\n    \"Write $(\\\\sigma, \\\\mu)$ as the assessment for all players.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.3 Consistency\\n\",\n    \"\\n\",\n    \"### 4.3.1 On the Path of Play\\n\",\n    \"\\n\",\n    \"Given any (pure or mixed) strategy profile $\\\\sigma$, an information set $h$ is said to be **on the path of play** if and only if the information set is reached with positive probability if players stick to $\\\\sigma$.\\n\",\n    \"\\n\",\n    \"If $h$ is not on the path of play, then we say it is **off the path of play**.\\n\",\n    \"\\n\",\n    \"### 4.3.2 Consistency\\n\",\n    \"\\n\",\n    \"Given any (pure or mixed) strategy profile $\\\\sigma$ and any information set $h$ on the path of play of $\\\\sigma$, a player's beliefs $\\\\mu$ at $h$ is said to be **consistent** with $\\\\sigma$ if and only if the beliefs are derived using the Bayes' rule and $\\\\sigma$.\\n\",\n    \"\\n\",\n    \"Moreover, even if $h$ is off the path of play, the beliefs must be derived using Bayes' rule and $\\\\sigma$ \\\"where possible\\\". \\n\",\n    \"\\n\",\n    \"Meaning of \\\"where possible\\\" may depend on the circumstances. For instance, if players tremble (make mistake) with very small probability so that $h$ is on the path, the beliefs must be very close to the ones derived using Bayes' rule and $\\\\sigma$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.4 Sequential Rationality\\n\",\n    \"\\n\",\n    \"Player $i$'s strategy $\\\\sigma_i$ is **sequentially rational** if and only if at each information set $h_i$, it maximises player $i$'s expected payoff conditional on his belief $\\\\mu_i$ and other players' strategies $\\\\sigma_{-i}$ from that node onward.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.5 Perfect Bayesian Nash Equilibrium \\n\",\n    \"\\n\",\n    \"A perfect Bayesian Nash equilibrium is an assessment ($\\\\sigma, \\\\mu$) of strategy profile $\\\\sigma$ and beliefs $\\\\mu$ such that\\n\",\n    \"\\n\",\n    \"* the strategy profile $\\\\sigma$ is **sequentially rational** given beliefs $\\\\mu$ and\\n\",\n    \"* Beliefs $\\\\mu$ are consistent with the strategy profile $\\\\sigma$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.6 Types of PBE\\n\",\n    \"\\n\",\n    \"There are mainly three types of perfect Bayesian equilibrium (PBE).\\n\",\n    \"\\n\",\n    \"### 4.6.1 Pooling Equilibria\\n\",\n    \"\\n\",\n    \"A PBE is pooling if different types of player use the same action. As such, no information is transmitted in their action. \\n\",\n    \"\\n\",\n    \"That is, $i(n(x, a))$ gains no information about $i(x)$'s type when $i(x)$ plays $a \\\\in A(x)$.\\n\",\n    \"\\n\",\n    \"### 4.6.2 Seperating Equilibria\\n\",\n    \"\\n\",\n    \"A PBE is seperating if different types of player use different actions. So players would perfectly learns their type in equilibrium.\\n\",\n    \"\\n\",\n    \"### 4.6.3 Semi-Seperating Equilibria\\n\",\n    \"\\n\",\n    \"A PBE is semi-seperating if its neither pooling nor seperating. Thus, there will be some learning about their types in equilibrium, but not perfect.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.7 Example - Gift Game\\n\",\n    \"\\n\",\n    \"We will study and apply these new concept by following a great [video](https://www.youtube.com/watch?v=43cFKBVMm90) on the gift game.\\n\",\n    \"\\n\",\n    \"### 4.7.1 Setting\\n\",\n    \"\\n\",\n    \"Suppose we have two players, 1 and 2, and 1 is trying to send a \\\"gift\\\" to 2. However, player 2 does not know the intension of player 1, and whether he is her friend (F) or her enemy (E) (this is 1's private information). As such, player 2 can choose either to accept the \\\"gift\\\" or reject the \\\"gift\\\".\\n\",\n    \"\\n\",\n    \"If player 1 has good intension, that is, he believes he is 2's friend. Then 1 would truely send 2 a gift, and both 1 and 2 would be happy about the gift and each receives 1 util if 2 accepts (A) the gift. However, if 2 reject (R) 1's gift, 1 would be heartbroken and receives -1 util while 2 receives 0 util.\\n\",\n    \"\\n\",\n    \"| friend |  A   |   R   |\\n\",\n    \"|--------|------|-------|\\n\",\n    \"|  $G^F$ | 1, 1 | -1, 0 |\\n\",\n    \"\\n\",\n    \"If player 1 is 2's enemy, and the \\\"gift\\\" is actually a prank, then if 2 foolishly accepts the \\\"gift\\\", she will be depressed and receives -1 util while 1 receives 1 util. However, if 2 rejects 1's \\\"gift\\\", she will receive 0 util while 1 will be upset about his failed scheme and receives -1 util.\\n\",\n    \"\\n\",\n    \"| enemy |   A   |   R   |\\n\",\n    \"|-------|-------|-------|\\n\",\n    \"| $G^E$ | 1, -1 | -1, 0 |\\n\",\n    \"\\n\",\n    \"Lastly, player 1 can also chooses not to send ($N^E$ / $N^F$) the gift at all, in which both players would receive 0 utility.\\n\",\n    \"\\n\",\n    \"|       *       |  A/R |\\n\",\n    \"|---------------|------|\\n\",\n    \"| $N^E$ / $N^G$ | 0, 0 |\\n\",\n    \"\\n\",\n    \"This is an incomplete information game as when 2 has to decide whether to accept 1's gift or not, she does not know 1's type. Let us denote this information set by $h$.\\n\",\n    \"\\n\",\n    \"Assume player 2 has some experience of receiving gifts and pranks, so she would have some prior belief on player 1's type (whether he is a friend or an enemy). Let us denote player 1 is a friend type with probability $p = p(F)$ and enemy type with probability $1 - p = p(E)$.\\n\",\n    \"\\n\",\n    \"Moreover, let us denote player 2's belief $\\\\mu_2 (F \\\\vert h)$ that she is receiving a gift from a friend by $q$, and a prank from an enemy by $1 - q = \\\\mu_2 (E \\\\vert h)$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 4.7.2 Player 1's Strategies\\n\",\n    \"\\n\",\n    \"Let us start with player 1's strategies. We know there are four possible (pure) strategy for player 1:\\n\",\n    \"\\n\",\n    \"* Give gift as a friend ($G^F$) and also give \\\"gift\\\" as an enemy ($G^E$);\\n\",\n    \"* Does not give a gift as a friend ($N^F$) not as an enemy ($N^E$);\\n\",\n    \"* Give gift as a friend ($G^F$) but not as an enemy ($N^E$);\\n\",\n    \"* Does not give a gift as a friend ($N^F$) but give \\\"gift\\\" as an enemy ($G^E$).\\n\",\n    \"\\n\",\n    \"We can see that the first two strategies are **pooling**, as player 2 cannot tell whether 1 is her friend or enemy by his actions, whereas the last two strategies are **seperating**.\\n\",\n    \"\\n\",\n    \"As such, in the first two cases, 2 does not learn anything new from 1's action, so we have $p = q$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 4.7.3 Case $G^F G^E$\\n\",\n    \"\\n\",\n    \"Since 2 knows 1 is a friend with probability $p$ and an enemy with probability $1 - p$, then if she decides to accept (A) the \\\"gift\\\", she gets \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  1 \\\\times p + (-1) \\\\times (1 - p) = 2p - 1\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"utils, whereas if she chooses to reject (R) 1, she receives 0 util. Then if $p \\\\geq \\\\frac{1}{2}$, 2 would accept the gift. \\n\",\n    \"\\n\",\n    \"Now if 2 is to accept the gift, player 1 would give her the gift regardless of his type to obtain 1 util, which is same as the strategy $G^F, G^E$. Hence,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  (G^F G^E, A)\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"is a pooling PBE with $q = p \\\\geq \\\\frac{1}{2}$.\\n\",\n    \"\\n\",\n    \"That is, if 2 believes 1 is more likely to be a friend, then she would accept the gift.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 4.7.4 Case $N^F N^E$\\n\",\n    \"\\n\",\n    \"Since if 1 does not give any gift to 2, then 2 can have any belief of 1's type: $q \\\\in [0, 1]$. If $q \\\\geq \\\\frac{1}{2}$, then we know from previous section that 2 would accept the gift and then 1 would prefer to give the gift. Hence, $N^F N^E$ would not be sequentially rational .\\n\",\n    \"\\n\",\n    \"On the other hand, if $q \\\\leq \\\\frac{1}{2}$, then 2 would reject the gift and 1 would prefer not to give the gift in order to not losing any util. Hence, $N^F N^E$ is sequentially rational and \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  (N^F N^E, R)\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"would be a pooling PBE with $q \\\\leq \\\\frac{1}{2}$.\\n\",\n    \"\\n\",\n    \"That is, if 2 believes 1 is more likely to be an enemy, then she would reject the gift and seeing this, 1 would prefer not send her a gift at all, even if he believes he is her friend.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 4.7.5 Case $G^F N^E$ and $N^F G^E$\\n\",\n    \"\\n\",\n    \"Since if 1 gives 2 a gift if and only if he is a friend type, then 2 would update her belief to be $q = 1$ if she sees a gift and thus, she would accept the gift. Now, we know the best response when 2 would accept the gift is $G^F G^E$. Hence, this cannot be a PBE.\\n\",\n    \"\\n\",\n    \"Similarly, if 1 plays $N^F G^E$ then 2 would update her belief to $q = 0$ as only an enemy would give a gift. So she would always reject the gift, and we now 1's best response against this is to play $N^F N^E$. Hence, this also cannot be a PBE.\\n\",\n    \"\\n\",\n    \"Thus, we see that there is no seperating equilibria in this game.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.8 Signaling Game\\n\",\n    \"\\n\",\n    \"The gift game example we discussed in **4.7** is in fact a signaling game. Signaling games are simple dynamic Bayesian games between two players, called the *sender* (S) and the *receiver* (R). The sender can have several types $t_1, \\\\ldots, t_n$ while the receiver only has one type. As such, the payoff for both players are determined by the sender's type $t_j$ and the actions chose by both players.\\n\",\n    \"\\n\",\n    \"In the signaling game, the informed player (i.e. the sender who knows her own type) usually makes the move first and the uninformed player (i.e. the receiver who does not know the sender's type) would then respond (if necessary). As we saw in **4.7**, the sender's action often incorporate some information about her own type which the receiver could use to update her belief on the sender's type.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.9 Screening Game\\n\",\n    \"\\n\",\n    \"Similar to a signaling game, a screening game is a game where the uninformed player moves first. That is, if we are to use the same terminology defined in the signaling game, it is the receiver who moves first while uninformed about the sender's type, and then the sender who knows her own type would respond if necessary.\\n\",\n    \"\\n\",\n    \"We will see an example in the next section.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4.10 Example - Adverse Selection\\n\",\n    \"\\n\",\n    \"Adverse selection is a problem of asymmetric information, where one party knows more than the other party when signing contractual agreements. Adverse selection is a problem frequently arises in the insurance industry, where the customers often withhold some of their own private information (e.g. medical conditions) from the insurer.\\n\",\n    \"\\n\",\n    \"### 4.10.1 Background\\n\",\n    \"\\n\",\n    \"Consider a game of adverse selection where the insurer is trying to offer a customer a health insurance product. Unkown to the insurer, the customer can be either healthy (type $t_G$) or unhealthy (type $t_B$).\\n\",\n    \"\\n\",\n    \"If the customer is healthy, then it would only cost the insurer on average $ \\\\$ $300 to cover but the customer is willing to pay up to $ \\\\$ $600 for insurance. However, if the customer is unhealthy, then it would cost the insurer on average $ \\\\$ $800 to cover and the customer is willing to pay up to $ \\\\$ $1000 for insurance.\\n\",\n    \"\\n\",\n    \"Suppose the insurer has its own model that predicts the customer is healthy with 0.8 probability and unhealthy with 0.2 probability. Based on his prior belief, the insurer can either choose to price his product using expected one period loss (L) of $ \\\\$ 400$ ($=0.8 \\\\times 300 + 0.2 \\\\times 800$) or at a more conservative minimax price (H) of $ \\\\$ $800.\\n\",\n    \"\\n\",\n    \"Based on insurer's pricing, the customer can either choose to buy (B) the insurance product, or not to buy (N) the insurance product.\\n\",\n    \"\\n\",\n    \"We will also make a simplifying assumption that the customer's payoff would be the difference between the actual price of the product and maximum price the customer is willing to pay for the product. For the insurer, we assume his payoff would be the difference between the price and the average cost of cover.\\n\",\n    \"\\n\",\n    \"The payoff matrix of the game is then:\\n\",\n    \"\\n\",\n    \"<table>\\n\",\n    \"<tr><th> Healthy Customer </th><th> Unhealthy Customer </th></tr>\\n\",\n    \"<tr><td>\\n\",\n    \"\\n\",\n    \"| $t_G$ |     B     |   N  |    \\n\",\n    \"|-------|-----------|------|    \\n\",\n    \"|   H   | 500, -200 | 0, 0 |    \\n\",\n    \"|   L   | 100, 200  | 0, 0 |    \\n\",\n    \"\\n\",\n    \"</td><td>\\n\",\n    \"\\n\",\n    \"| $t_B$ |     B     |  N   |\\n\",\n    \"|-------|-----------|------|\\n\",\n    \"|   H   |  0, 200   | 0, 0 |\\n\",\n    \"|   L   | -400, 600 | 0, 0 |\\n\",\n    \"\\n\",\n    \"</td></tr> </table>\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"### 4.10.2 Solving for Perfect Bayesian Equilibrium\\n\",\n    \"\\n\",\n    \"Screening games are usually easier to solve for PBE comparing to signaling games, as we can often determine player 2's (i.e. the customer in this example) best response via backward induction. \\n\",\n    \"\\n\",\n    \"If the insurer sets the price high ($ \\\\$ $800), then the customer would be better off if he decline the offer when he is healthy (0 > -200). In all other scenarios, we see the customer would be better off if he accepts the offer.\\n\",\n    \"\\n\",\n    \"Updating the payoff table we have:\\n\",\n    \"\\n\",\n    \"<table>\\n\",\n    \"<tr><th> Healthy Customer </th><th> Unhealthy Customer </th></tr>\\n\",\n    \"<tr><td>\\n\",\n    \"\\n\",\n    \"| $t_G$ |     -     |  \\n\",\n    \"|-------|-----------|   \\n\",\n    \"|   H   | 0, 0      |   \\n\",\n    \"|   L   | 100, 200  |   \\n\",\n    \"\\n\",\n    \"</td><td>\\n\",\n    \"\\n\",\n    \"| $t_B$ |     -     |\\n\",\n    \"|-------|-----------|\\n\",\n    \"|   H   |  0, 200   |\\n\",\n    \"|   L   | -400, 600 |\\n\",\n    \"\\n\",\n    \"</td></tr> </table>\\n\",\n    \"\\n\",\n    \"Now, we see insurer's payoff when setting the price high (H) is 0 and his expected payoff when setting the price low (L) is also 0 ($=0.8 \\\\times 100 - 0.2 \\\\times 400$). Hence the insurer is indifferent between setting the price high or low.\\n\",\n    \"\\n\",\n    \"Hence, we have two (pure) PBE: $\\\\left( H, s_H \\\\right)$ and $\\\\left( L, B \\\\right)$ where\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  S_H (t) = \\\\begin{cases}\\n\",\n    \"              N & \\\\text{ if } t = t_G;\\\\\\\\\\n\",\n    \"              B & \\\\text{ if } t = t_B\\n\",\n    \"            \\\\end{cases}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"against insurer's belief that the customer is healthy with probability 0.8.\\n\",\n    \"\\n\",\n    \"In this game, we see that when the insurer sets high price, only unhealthy customer has incentive to accept the offer, which is a classical example of adverse selection. \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# 5. Evolutionary Game Theory\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5.1 Motivating Example - Hawk-Dove Games\\n\",\n    \"\\n\",\n    \"Consider a symmetric example of Hawk-Dove game where two identical individuals compete for resources of a fixed value $V$. Each of the individual can choose to follow \\n\",\n    \"\\n\",\n    \"> **Hawk**: Initiate aggressive behaviour, not stopping until injured or until one's opponent backs down.<br>\\n\",\n    \"> **Dove**: Retreat immediately if one's opponent initiates aggressive behaviour.\\n\",\n    \"\\n\",\n    \"If both individuals initiate aggressive behaviour (both playing *Hawk*), then each individual has equal chances of winning, in which one obtain the resource $V$, and losing, in which one would be injured and suffer from cost of conflict $C$. If a *Dove* meets a *Hawk*, *Dove* immediately retreats and *Hawk* would obtain all the resources $V$. When two *Dove* meet, the resource is equally shared and both individuals would obtain $\\\\frac{V}{2}$. \\n\",\n    \"\\n\",\n    \"The payoff is summarised in the following payoff matrix.\\n\",\n    \"\\n\",\n    \"|   *  |               Hawk               |              Dove            |\\n\",\n    \"|------|----------------------------------|------------------------------|\\n\",\n    \"| Hawk | $\\\\frac{V-C}{2}$, $\\\\frac{V-C}{2}$ |              V, 0            |\\n\",\n    \"| Dove |               0, V               | $\\\\frac{V}{2}$, $\\\\frac{V}{2}$ |\\n\",\n    \"\\n\",\n    \"Note that in the Hawk-Dove game, we generally assume $C > V > 0$, that is, the cost of fight is higher than the value of resources. If $C \\\\leq V$, then the game is essentially a Prisoner's Dilemma game where (*Hawk*, *Hawk*) is the only Nash equilibrium.\\n\",\n    \"\\n\",\n    \"### 5.1.1 Quick Example\\n\",\n    \"\\n\",\n    \"If we take $C = 10$ and $V = 6$, the payoff matrix now becomes \\n\",\n    \"\\n\",\n    \"|   *  |               Hawk               |              Dove            |\\n\",\n    \"|------|----------------------------------|------------------------------|\\n\",\n    \"| Hawk | -2, -2 |              6, 0            |\\n\",\n    \"| Dove |               0, 6               | 3, 3 |\\n\",\n    \"\\n\",\n    \"If we use $H$ to denote *Hawk*, and $D$ to denote *Dove*, the Nash equilibrium is then\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  NE = \\\\left \\\\{ (H, D), (D, H), \\\\left( \\\\frac{3}{5}H + \\\\frac{2}{5}D, \\\\frac{3}{5}H + \\\\frac{2}{5}D \\\\right) \\\\right \\\\}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"### 5.1.2 Re-Interpretation\\n\",\n    \"\\n\",\n    \"If we let $p$ be the probability or proportion of an animal from a given population being a *Hawk* type, and $1 - p$ be the probability of an animal being a *Dove* type, then the expected payoff of an animal intereacting with another animal randomly drawn from the population can be summerised by the graph below.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"image/png\": \"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\\n\",\n      \"text/plain\": [\n       \"<Figure size 432x288 with 1 Axes>\"\n      ]\n     },\n     \"metadata\": {},\n     \"output_type\": \"display_data\"\n    }\n   ],\n   \"source\": [\n    \"%matplotlib inline\\n\",\n    \"import matplotlib.pyplot as plt; import numpy as np; plt.style.use('seaborn-whitegrid');\\n\",\n    \"fig = plt.figure(); ax = plt.axes(); p = np.linspace(0, 1, 1000);\\n\",\n    \"ax.plot(p, 6 - 8 * p, label = 'Hawk'); ax.plot(p, 3 * (1 - p), label = 'Dove');\\n\",\n    \"plt.legend(); plt.title(\\\"Hawk-Dove Fitness\\\"); plt.xlabel(\\\"p\\\"); plt.ylabel(\\\"fitness\\\");\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"In **evolutionary biology**, we often use the term *fitness* instead of *payoff*, and the species with higher *fitness* tends to dominate (survival of the fittest). \\n\",\n    \"\\n\",\n    \"We see that when $p$ is small $\\\\left( p < \\\\frac{3}{5} = 0.6 \\\\right)$, that is, the population is majorly *Dove* type, *Hawk* type has better fitness, so the population should move in a direction that reproduce more *Hawk* type that would increase $p$. On the contrary, when $p$ is large ($p > 0.6$), the *Dove* type has more advantage over the *Hawk* type and hence the population would reproduce more *Dove* type which reduces $p$. Therefore, we should have $\\\\frac{3}{5}$ *Hawk* type and $\\\\frac{2}{5}$ *Dove* type in the equilibrium population.\\n\",\n    \"\\n\",\n    \"We will elaborate on this idea further in the next section.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5.2 Evolutionary Game Theory\\n\",\n    \"\\n\",\n    \"The main idea of evolutionary biology is that **genes** are the prime determinants of observable characteristics, called *fitness*, in a given environment. This means that genes which provide greater fitness get increased representation in the population.\\n\",\n    \"\\n\",\n    \"In comparison to regular game theory, where rational players consciously make strategic decisions to optimises their interest, evolutionary game theory concerns with \\n\",\n    \"\\n\",\n    \"> which behaviour will persist in a population.\\n\",\n    \"\\n\",\n    \"Game theoretic concept will continue to apply in evolutionary game theory under the new interpretation.\\n\",\n    \"\\n\",\n    \"| Regular Game Theory Notion |    Evolutionary Game Theory Notion    |\\n\",\n    \"|----------------------------|---------------------------------------|\\n\",\n    \"|          Players           |              Organisms                |\\n\",\n    \"|       Pure Strategy        |        Genes / Behaviours             |\\n\",\n    \"|       Mixed Strategy       |     Distribution of Genes/ Behaviours |\\n\",\n    \"|       Payoff               |             Fitness                   |\\n\",\n    \"|    Rational Behaviour      |          Natural Selectoin            |\\n\",\n    \"\\n\",\n    \"In evolutionary game theory, we assume the success of an organism depends on how it interacts with other organisms. That is, fitness is comparative and must be evaluated in the context of full population in which it lives. \\n\",\n    \"\\n\",\n    \"To help us understand more, we will go through another example.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5.3 Example: Beetles of Another Kind\\n\",\n    \"\\n\",\n    \"Let us consider a world of beetles, where its survival fitness depends on finding and processing food effectively. All beetles are similar and of the same size. Now, suppose a mutation occurred where some beetles are born with larger body sizes. Larger beetles need more food to sustain, therefore they are have less fitness comparing to smaller beetles. However, a larger beetle would get more food due to its size advantage comparing to smaller beetles. And when two beetles of similar size meet, they would share the resource.\\n\",\n    \"\\n\",\n    \"A suitable matrix that satisfies these assumption is given below.\\n\",\n    \"\\n\",\n    \"| * | Small | Large |\\n\",\n    \"|---|---|---|\\n\",\n    \"| Small | 6, 6 | 1, 10 |\\n\",\n    \"| Large | 10, 1 | 4, 4 |\\n\",\n    \"\\n\",\n    \"Our interest is to study the long term consequences of this mutation to the beetles' world. \\n\",\n    \"\\n\",\n    \"However, Nash equilibrium would be unsuitable in determing the solution for this evolutionary game. This is because beetle's size is not a strategy where the beetle can choose, but hard-wired in their genes. As such, we will introduce a new solution concept - *evolutionary stable strategy* (ESS).\\n\",\n    \"\\n\",\n    \"### 5.3.1 Is Being A Small Beetle Evolutionary Stable?\\n\",\n    \"\\n\",\n    \"In order for a strategy to be evolutionary stable, it must have the property that if almost every member of the population follows it, no mutant (an individual who adopts novel strategy) can successfully invade. \\n\",\n    \"\\n\",\n    \"Suppose our population of small beetles is invaded by large beetles such that the new population is now composed of $p$ large beetles and $1 - p$ small beetles. Then the expected payoff to a small beetle in a random interaction is \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  6 (1 - p) + p = 6 - 5p.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"The expected payoff to a large beetle is then\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  10 ( 1 - p) + 4 p = 10 - 6p.\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 2,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"image/png\": \"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\\n\",\n      \"text/plain\": [\n       \"<Figure size 432x288 with 1 Axes>\"\n      ]\n     },\n     \"metadata\": {},\n     \"output_type\": \"display_data\"\n    }\n   ],\n   \"source\": [\n    \"%matplotlib inline\\n\",\n    \"import matplotlib.pyplot as plt; import numpy as np; plt.style.use('seaborn-whitegrid');\\n\",\n    \"fig = plt.figure(); ax = plt.axes(); p = np.linspace(0, 1, 1000);\\n\",\n    \"ax.plot(p, 6 - 5 * p, label = 'Small'); ax.plot(p, 10 - 6 * p, label = 'Large');\\n\",\n    \"plt.title(\\\"Expected Payoff When p Large Beetls Invade\\\");\\n\",\n    \"plt.legend(); plt.xlabel(\\\"p\\\"); plt.ylabel(\\\"Fitness\\\");\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"We see that for any $p \\\\in [0, 1]$, the payoff of a large beetle will always exceed payoff of a small beetle. So when a few large beetles mutants get introduced into a population of small beetles incumbents, they will get most of the food in most of the competitions and the small beetles can not drive out the big beetles. \\n\",\n    \"\\n\",\n    \"Therefore, small is not evolutionary stable.\\n\",\n    \"\\n\",\n    \"### 5.3.2 Is Being A Large Beetle Evolutionary Stable?\\n\",\n    \"\\n\",\n    \"If in another beetle world, large beetles are the incumbents and small beetles are the mutants, then the corresponding payoff would be the followings.\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 3,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"image/png\": \"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\\n\",\n      \"text/plain\": [\n       \"<Figure size 432x288 with 1 Axes>\"\n      ]\n     },\n     \"metadata\": {},\n     \"output_type\": \"display_data\"\n    }\n   ],\n   \"source\": [\n    \"%matplotlib inline\\n\",\n    \"import matplotlib.pyplot as plt; import numpy as np; plt.style.use('seaborn-whitegrid');\\n\",\n    \"fig = plt.figure(); ax = plt.axes(); p = np.linspace(0, 1, 1000);\\n\",\n    \"ax.plot(p, 1 + 5 * p, label = 'Small'); ax.plot(p, 4 + 6 * p, label = 'Large');\\n\",\n    \"plt.title(\\\"Expected Payoff When p Small Beetls Invade\\\");\\n\",\n    \"plt.legend(); plt.xlabel(\\\"p\\\"); plt.ylabel(\\\"Fitness\\\");\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"Hence, we see small beetles mutants cannot survive in the disadvantaged world of large beetles as they will lose in almost every competition for food. Hence, the population of large beetles will resist the invasion of small beetles and large is thus evolutionary stable.\\n\",\n    \"\\n\",\n    \"### 5.3.3 Insight from the Game\\n\",\n    \"\\n\",\n    \"It is not hard to notice that the structure of the game is the same as the structure of Prisoners' dilemma. (Large, Large) would be the Nash equilibrium of the game under regular game theory. However, the crucial difference is that no rationality is assumed in the evolutionary version. Rationality is always criticised as what seperates game theory from actual lab experiments. Hence, evolutionary game theory promotes a way for us to weaken the strong rationality assumption in explaining human behaviours.\\n\",\n    \"\\n\",\n    \"The game also shows a different path from our usual perception of \\\"survival of the fitness\\\". In our game, we see evolution is causing the fitness to decrease over time, this is due to the increase in hostility of the environment.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5.4 Evolutionary Stable Strategy\\n\",\n    \"\\n\",\n    \"To formalise our ideas about evolutionary stable strategy, if we let $S$ to be a set of pure strategies, $\\\\Delta (S)$ to be the set of all distributions over $S$, and $F: \\\\Delta (S) \\\\rightarrow \\\\mathbb{R}$ be the fitness function, where $F(\\\\sigma)$ is the total fitness of an individual adopting strategy $\\\\sigma \\\\in \\\\Delta (S)$. \\n\",\n    \"\\n\",\n    \"Assuming all individuals of the population has an initial fitness $F_0$. Let $\\\\Delta F(\\\\sigma, \\\\mu)$ be the change in fitness for an individual following strategy $\\\\sigma$ against opponent's strategy $\\\\mu$. \\n\",\n    \"\\n\",\n    \"Then if $\\\\sigma$ is an evolutionary stable strategy, and $\\\\mu$ is a mutant strategy trying to invade the population, then \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  F(\\\\sigma) = F_0 + (1 - p) \\\\Delta F(\\\\sigma, \\\\sigma) + p \\\\Delta F(\\\\sigma, \\\\mu),\\\\\\\\\\n\",\n    \"  F(\\\\mu) = F_0 + (1 - p) \\\\Delta F(\\\\mu, \\\\sigma) + p \\\\Delta F(\\\\mu, \\\\sigma),\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"where $p$ is the proportion of the population following the mutant strategy $\\\\mu$.\\n\",\n    \"\\n\",\n    \"Since $\\\\sigma$ is evolutionary stable, then it must be the case that $F(\\\\sigma) > F(\\\\mu)$. Moreover, Maynard Smith and Price argues that it is also required *either* that\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\Delta F(\\\\sigma, \\\\sigma) > \\\\Delta F(\\\\mu, \\\\sigma),\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"*or* that\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\Delta F(\\\\sigma, \\\\sigma) = \\\\Delta F(\\\\mu, \\\\sigma) \\\\text{ and } \\\\Delta F(\\\\sigma, \\\\mu) > \\\\Delta F(\\\\mu, \\\\mu).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"### 5.4.1 Interpretation\\n\",\n    \"\\n\",\n    \"The first requirement is sometimes called strict Nash equilibrium, where all incumbents following $\\\\sigma$ has better fitness than mutants following $\\\\mu$ against other incumbents. If this holds, mutants cannot successfully invade and they will eventually die out. \\n\",\n    \"\\n\",\n    \"The second requirement is sometimes called Maynard Smith's second condition, where if the mutants is neutral with respect to the payoff against incumbents, then for incumbents to resist the invasion of mutant, it must be the case that the incumbents perform better against the mutants than the mutants performing against their own kinds. \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5.5 Replicator Dynamical Model\\n\",\n    \"\\n\",\n    \"We will briefly introduce a common model used in evolutionary game theory - the replicator dynamical model. First, let us consider the normal form representation of an evolutionary game:\\n\",\n    \"\\n\",\n    \"|     *    | $s_1$    | $s_2$    | $\\\\ldots$ | $s_j$    | $\\\\ldots$ | $s_n$    |\\n\",\n    \"|----------|----------|----------|----------|----------|----------|----------|\\n\",\n    \"| $s_1$    | $w_{11}$ | $w_{12}$ | $\\\\ldots$ | $w_{1j}$ | $\\\\ldots$ | $w_{1n}$ |\\n\",\n    \"| $s_2$    | $w_{21}$ | $w_{22}$ | $\\\\ldots$ | $w_{2j}$ | $\\\\ldots$ | $w_{2n}$ |\\n\",\n    \"| $\\\\vdots$ | $\\\\vdots$ | $\\\\vdots$ | $\\\\ddots$ | $\\\\vdots$ | $\\\\vdots$ | $\\\\vdots$ |\\n\",\n    \"| $s_i$    | $w_{i1}$ | $w_{i2}$ | $\\\\ldots$ | $w_{ij}$ | $\\\\ldots$ | $w_{in}$ |\\n\",\n    \"| $\\\\vdots$ | $\\\\vdots$ | $\\\\vdots$ | $\\\\ddots$ | $\\\\vdots$ | $\\\\vdots$ | $\\\\vdots$ |\\n\",\n    \"| $s_n$    | $w_{n1}$ | $w_{n2}$ | $\\\\ldots$ | $w_{nj}$ | $\\\\ldots$ | $w_{nn}$ |\\n\",\n    \"\\n\",\n    \"where \\n\",\n    \"\\n\",\n    \"* $S = \\\\{s_1, \\\\ldots, s_n\\\\}$ is a set of (pure) strategies.\\n\",\n    \"* $w_{ij}$ is the payoff of an individual who adpots strategy $s_i \\\\in S$ interacting with an individal who adopts strategy $s_j \\\\in S$.\\n\",\n    \"* $N_i$ be the number of individuals who adopt strategy $s_i \\\\in S$, and $N = \\\\sum_i N_i$ be total number of replicators.\\n\",\n    \"* $x_i = \\\\frac{N_i}{N}$ be share of population playing strategy $s_i \\\\in S$.\\n\",\n    \"* $w_i (x) = \\\\sum_j x_j w_{ij}$ be the fitness of strategy $i$ against the current state $x$ (note that this is essentially just the expected fitness for strategy $i$). \\n\",\n    \"* Lastly, let $\\\\overline{w} = \\\\sum_i x_i w_i (x)$ be the average fitness of the population.\\n\",\n    \"\\n\",\n    \"Then, replicator dynamical model assumes replicators reproduce with regard to their fitness in relation to the fitness of others. Hence, in general, the replicators whose fitness is larger (smaller) than the average fitness of the population will increase (decrease) their share in the population.\\n\",\n    \"\\n\",\n    \"### 5.5.1 Replicator Equation\\n\",\n    \"\\n\",\n    \"Under these assumption, for each $i$, each individual from $s_i$ grows at a rate of $w_i (x)$, hence $N_i$ grows at a rate \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\frac{d N_i}{dt} = N_i w_i (x).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"The total population then grows at a rate\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\frac{dN}{dt} = N \\\\overline{w}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Hence, for $x_i = \\\\frac{N_i}{N}$, using quotient rule and chain rule, we have\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\frac{dx_i}{dt} = \\\\frac{d}{dt} \\\\left( \\\\frac{N_i}{N}\\\\right) = \\\\frac{N \\\\frac{dN_i}{dt} - N_i \\\\frac{dN}{dt}}{N^2} = \\\\frac{N_i N}{N^2} \\\\left[ w_i (x) - \\\\overline{w} \\\\right].\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Simplifying gives\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\overset{.}{x}_i = x_i \\\\left[ w_i (x) - \\\\overline{w} \\\\right], \\\\hspace{7mm} i = 1, \\\\ldots, n.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Our goal is to find the attractors, steady states where the system tends to evolve from various initial states. These states are called *evolutionary stable states*, which have strong correlation with the evolutionary stable strategies. \"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5.6 Example: Prisoners' Dilemma\\n\",\n    \"\\n\",\n    \"Consider the general version of prisoners' dilemma game with the normal form representation\\n\",\n    \"\\n\",\n    \"| * | C | D |\\n\",\n    \"|---|---|---|\\n\",\n    \"| C | R | S | \\n\",\n    \"| D | T | P |\\n\",\n    \"\\n\",\n    \"where we use $C$ to represent cooporate, $D$ to represent defect, and $T, R, P, S$ are constants such that \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  T > R > P > S \\\\text{ and } R > \\\\frac{T + P}{2}.\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"To justify this, we use $T$ to denote *temptation*, $R$ to denote *reward* from cooporation, $P$ to denote *punishment* for mutual defection, and $S$ is the *sucker*'s payoff. The value of $T$ is the highest to tempt players to cheat, and the value of $S$ is the lowest to describe the terrible feeling of being betrayed. The order of $R$ and $P$ is then self-explanatory. \\n\",\n    \"\\n\",\n    \"It is conventional to also assume $R > \\\\frac{T + P}{2}$ or else alternating rounds between cooporation and defect leads to a greater payoff than pure cooporation.\\n\",\n    \"\\n\",\n    \"If we let $x_C$ to be the proportion of the population that always cooporate, and $x_D = 1 - x_C$ be the proportion of the population that always cheat, then the replicator equation shows for $i \\\\in \\\\{C, D\\\\}$,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\overset{.}{x_i} = x_i \\\\left[ w_i (x) - \\\\overline{w} \\\\right].\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"After substitution, we have\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  w_C (x) = x_C w_{CC} + x_D w_{CD} = x_C R + w_D S = S + x_C (R - S).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Similarly,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  w_D (x) = P + x_C (T - P).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"Hence,\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"\\\\begin{align*}\\n\",\n    \"  w_C (x) - \\\\overline{w} &= w_C (x) - x_C w_C (x) - x_D w_D (x)\\\\\\\\\\n\",\n    \"                         &= (1 - x_C) (w_C (x) - w_D (x))\\\\\\\\\\n\",\n    \"                         &= (1 - x_C) \\\\left[ (1 - x_C) (S - P) + x_C (R - T) \\\\right] < 0,\\n\",\n    \"\\\\end{align*}\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"since $S < P$ and $R < T$ from definition. Hence, $w_C (x) - \\\\overline{w} < 0$ and C will decay exponentially and eventually dies out. Similarly, $w_D (x) - \\\\overline{w} > 0$ so the population will eventually be filled with always defect people and thus the evolutionary stable state is $\\\\left(x_C, x_D\\\\right) = (0, 1)$.\\n\",\n    \"\\n\",\n    \"One can check that this is also the evolutionary stable strategy of the game.\\n\",\n    \"\\n\",\n    \"More material on evolutionary stable strategy and replicator equation can be found [here](http://www.cse.cuhk.edu.hk/~cslui/CSC6480/replicator.pdf).\\n\",\n    \"\\n\",\n    \"More examples can be found [here](http://systems-sciences.uni-graz.at/etextbook/gametheory/replicator.html).\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# 6. Repeated Game with Perfect Monitoring\\n\",\n    \"\\n\",\n    \"In the last section, we see animals interact over time to determine the fittest strategies by evolution. For most strategic situation in the human world, players interact repeatedly over time. This includes continuous transactions and negotiations between firms and clients. The simplest model that captures this notion of ongoing interaction is the repeated game, which solely focus on the effect of repetition. \\n\",\n    \"\\n\",\n    \"In this section, we assumes the game is perfectly monitored, that is, all players' actions are directly observable by all players. We will first go through one of the most famous example of repeated games - you guessed it - the repeated prisoners' dilemma game.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 6.1 Motivating Example: Repeated Prisoners' Dilemma\\n\",\n    \"\\n\",\n    \"Consider the following normal form representation of prisoners' dilemma game.\\n\",\n    \"\\n\",\n    \"| * |   C   |   D   |\\n\",\n    \"|---|-------|-------|\\n\",\n    \"| C | 1, 1  | -1, 2 |\\n\",\n    \"| D | 2, -1 | 0, 0  |\\n\",\n    \"\\n\",\n    \"Once again, we use $C$ to denote cooporation, and $D$ to denote defection. The unique Nash equilibrium is once again $(D, D)$.\\n\",\n    \"\\n\",\n    \"### 6.1.1 Twice Repeated Prisoners' Dilemma\\n\",\n    \"\\n\",\n    \"Now, we assume the game will be played twice. That is, the game will be broken down into two stages. In the first stage, players play the prisoners' dilemma game once and receive their payoffs. Each player will remember what the other player chose in the first stage, and they will then play the same game again by deciding on their actions simultanously based on what they observe. The payoff for each player will be the total payoff from each stage game (stage 1 and 2).\\n\",\n    \"\\n\",\n    \"Note that we can represent this game using extensive form with incomplete information and solve it using backward induction. \\n\",\n    \"\\n\",\n    \"Let $g_i (a_i, a_{-i})$ be the payoff of the last stage game for player $i$ who chose action $a_i$ against opponent's action $a_{-i}$. Suppose in the first stage game, two players made their actions simultanously and received a payoff of $P_1$ and $P_2$ for player 1 and 2 respectively. Then, it is not hard to see that the maxima of the payoff function does not depend on additive constant:\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\arg \\\\max_a g_i (a_i, a_{-i}) + P_i = \\\\arg \\\\max_a g_i (a_i, a_{-i}).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"For instance, if player 1 chose $C$ in the first round and player 2 chose $D$, then the overall payoff matrix at the last stage is\\n\",\n    \"\\n\",\n    \"| * |   C  |   D   |\\n\",\n    \"|---|------|-------|\\n\",\n    \"| C | 0, 3 | -2, 4 |\\n\",\n    \"| D | 1, 1 | -1, 2 |\\n\",\n    \"\\n\",\n    \"where the dominant strategy of the game and the unique Nash equilibria of the game is still $(D, D)$.\\n\",\n    \"\\n\",\n    \"Hence, we know no matter what happened in the first stage, both players would prefer to choose $D$ in the last stage. Knowing this, the first stage game is essentially just a single prisoners' dilemma game and hence both players would also choose $(D, D)$ in the first stage. \\n\",\n    \"\\n\",\n    \"One can use the same logic to argue for any finitely repeated prisoners' dilemma game, the unique subgame perfect equilibria (SPE) is to defect (D) every single period.\\n\",\n    \"\\n\",\n    \"However, one may suspect the SPE of finitely repeated game is just the combination of NE in each stage game. Interestingly, this is not true and we will construct a counter example in the next section.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 6.2 Counter Example and Trigger Strategy\\n\",\n    \"\\n\",\n    \"Consider a twice repeated game with the following stage game:\\n\",\n    \"\\n\",\n    \"| * |   L  |   R  |   C  |\\n\",\n    \"|---|------|------|------|\\n\",\n    \"| U | 4, 3 | 0, 0 | 1, 4 |\\n\",\n    \"| D | 0, 0 | 2, 1 | 0, 0 |\\n\",\n    \"\\n\",\n    \"At each stage, player 1 can choose either *up* (U) or *down* (D) and player 2 can choose either *left* (L), *right* (R), or *center* (C). \\n\",\n    \"\\n\",\n    \"If this game is played only once, it is clear that $L$ is strictly dominated and the the pure NE is $\\\\{(D, R), (U, C)\\\\}$.\\n\",\n    \"\\n\",\n    \"However, we see that $(D, R)$ is Pareto dominated by $(U, L)$. Then let us ask ourselves: would $(U, L)$ be played in a SPE in the twice repeated game?\\n\",\n    \"\\n\",\n    \"Consider the following strategy for player 1:\\n\",\n    \"\\n\",\n    \"> Play $U$ in stage one. If player 2 played $L$, then play $U$ in stage two, else play $D$.\\n\",\n    \"\\n\",\n    \"If player 2 played $R$ in stage one, then her maximum total payoff of the game is 1, where she plays $R$ again and player 1 punishes her for not playing $L$ by playing $D$. \\n\",\n    \"\\n\",\n    \"Similarly, if player 2 played $C$ in stage one, then her maximum total payoff is 5 (4 from stage 1 from $(U, C)$ and 1 from stage 2 from $(D, R)$.\\n\",\n    \"\\n\",\n    \"However, if player 2 complies and played $L$ in stage 1, then her maximum payoff is 7 (3 from stage 1 from $(U, L)$ and 4 from stage 2 from $(U, C)$). Hence, player 2 should pretend to work with player 1 by choosing $L$ in the first stage and then maximises her own payoff by playing $C$ in stage 2.\\n\",\n    \"\\n\",\n    \"Being insecure herself, player 2 can also propose the strategy:\\n\",\n    \"\\n\",\n    \"> Play $L$ in stage one. If player 1 played $U$, then play $C$ in stage two, else play $R$.\\n\",\n    \"\\n\",\n    \"This strategy will capture the maximum payoff when player 1 sticks to his promise, and also threat to play $R$ if player 1 betrays his words. We can use the same logic as above to check that these two strategies are mutual best responses against each other and hence they are SPE.\\n\",\n    \"\\n\",\n    \"As such, we can see even a strictly dominated strategy can occur in the SPE if both players adopt some trigger strategies that threatens to decrease others' maximum gain in the whole game. In another words, it is entirely possible to sustain cooperations in a negotiation with suitable and credible threats.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 6.3 Another Example: Infinitely Repeated Prisoners' Dilemma\\n\",\n    \"\\n\",\n    \"Now, suppose instead of two times, the prisoners' dilemma game is played infinite number of times.\\n\",\n    \"\\n\",\n    \"| * |   C   |   D   |\\n\",\n    \"|---|-------|-------|\\n\",\n    \"| C | 1, 1  | -1, 2 |\\n\",\n    \"| D | 2, -1 | 0, 0  |\\n\",\n    \"\\n\",\n    \"To ensure we have finite comparable payoffs, let us assume each player is impatient and has a discount factor of $\\\\delta < 1$. That is, a dollar tomorrow is worth less than a dollar today. Moreover, let $a_i^t$ be player $i$'s action in the $t$-th stage, $t = 0, 1, \\\\ldots$, and $g_i \\\\left( a_i^t, a_{-i}^t \\\\right)$ be the payoff of the $t$-th stage given $i$ played $a_i^t$ and $-i$ played $a_{-i}^t$. Then, player $i$'s total payoff is\\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i \\\\left( a^1_i, a^1_{-i}, a^2_i, a^2_{-i}, \\\\ldots \\\\right) = \\\\sum_{t = 0}^\\\\infty \\\\delta^t g_i \\\\left( a^t_i, a^t_{-i} \\\\right).\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"### 6.3.1 One Shot Deviation Principle\\n\",\n    \"\\n\",\n    \"In finite games or infinitely repeated games with discounting, a set of strategy is subgame perfect equilibrium (SPE) if and only if no player can profitably deviate from his strategy at a single stage and maintain his strategy everywhere else.\\n\",\n    \"\\n\",\n    \"For instance, suppose the prisoners' dilemma game is repeated 3 times, then each player has $2^3$ number of different strategies. However, the one shot deviation principle says that to check whether $CCC$ is a SPE, we only need to check $\\\\textbf{D}CC$, $C\\\\textbf{D}C$ and $CC\\\\textbf{D}$. If none of these strategies yield a better payoff than $CCC$, then $CCC$ is SPE. \\n\",\n    \"\\n\",\n    \"This is a very useful principle as it reduces complexity of the problem from exponential to linear.\\n\",\n    \"\\n\",\n    \"### 6.3.2 Grim Trigger\\n\",\n    \"\\n\",\n    \"Grim Trigger is the strategy\\n\",\n    \"\\n\",\n    \"> $I$.  Play C in every period unless the opponent plays $D$, in which go to $II$.<br>\\n\",\n    \"> $II$. Play D forever.\\n\",\n    \"\\n\",\n    \"That is, keep cooporating until the opponent defects, in which defect forever. This is a punishment strategy which threatens to defect forever to persuade the opponent to cooporate. \\n\",\n    \"\\n\",\n    \"### 6.3.3 Proposition\\n\",\n    \"\\n\",\n    \"If $\\\\delta \\\\geq \\\\frac{1}{2}$, ($C$, $C$) is the SPE of the repeated prisoners' dilemma game if both players follow the Grim trigger strategy. \\n\",\n    \"\\n\",\n    \"#### 6.3.3.1 Proof\\n\",\n    \"\\n\",\n    \"Suppose up to time $t$, $D$ has never been played. Then $i$'s payoff looking forward are\\n\",\n    \"\\n\",\n    \"> Play $C$: $1 + \\\\delta + \\\\delta^2 + \\\\ldots = \\\\frac{1}{1 - \\\\delta}$;<br>\\n\",\n    \"> Play $D$: $2 + 0\\\\delta + 0\\\\delta^2 + \\\\ldots = 2$;\\n\",\n    \"\\n\",\n    \"Hence, $i$ should play $C$ if $\\\\delta \\\\geq \\\\frac{1}{2}$. Suppose $D$ is played at time $t$, then $-i$ will always play $D$ and $i$'s payoffs looking forward are\\n\",\n    \"\\n\",\n    \"> Play $C$: $-1 + 0\\\\delta + 0\\\\delta^2 + \\\\ldots = -1$;<br>\\n\",\n    \"> Play $D$: $0 + 0\\\\delta + 0\\\\delta^2 + \\\\ldots = 0$;\\n\",\n    \"\\n\",\n    \"Hence, $i$ should play $D$. Therefore, by the one shot principle, both player playing the Grim trigger strategy is the SPE, in which each round $(C, C)$ will be played.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 6.4 General Model\\n\",\n    \"\\n\",\n    \"A $k$-repeated game $G^k (\\\\delta)$ with discount factor $\\\\delta$ is the game consist of\\n\",\n    \"\\n\",\n    \"* A set of players $\\\\mathcal{I} = \\\\{ 1, 2, \\\\ldots, I \\\\}$.\\n\",\n    \"* A set of payoff functions $g_i: A \\\\rightarrow \\\\mathbb{R}$, $i = 1, \\\\ldots, I$.\\n\",\n    \"* A normal form game $G = (A, g)$. $G$ is repeated at $t = 0, \\\\ldots, k - 1$, where players discount at $\\\\delta$ and observe all previous actions. \\n\",\n    \"* A history $H^t = \\\\left\\\\{ \\\\left( a_1^0, a_2^0, \\\\ldots, a_I^0\\\\right), \\\\ldots, \\\\left( a_1^{t - 1}, \\\\ldots, a^{t - 1}_I\\\\right)\\\\right\\\\}$.\\n\",\n    \"* A strategy $s_{it}: H^t \\\\rightarrow A_i$.\\n\",\n    \"* A payoff \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  u_i (s_i, s_{-i}) = \\\\sum_{i = 1}^\\\\infty \\\\delta^t g_i (a_i, a_{-i}).\\n\",\n    \"$$\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 6.5 Individual Rationality\\n\",\n    \"\\n\",\n    \"### 6.5.1 Min-max payoff \\n\",\n    \"\\n\",\n    \"Player $i$'s min-max payoff is \\n\",\n    \"\\n\",\n    \"$$\\n\",\n    \"  \\\\underline{v}_i = \\\\min_{\\\\sigma_{-i}} \\\\max_{\\\\sigma_{i}} g_i (\\\\sigma_i, \\\\sigma_{-i})\\n\",\n    \"$$\\n\",\n    \"\\n\",\n    \"### 6.5.2 Individual Rationality\\n\",\n    \"\\n\",\n    \"In any Nash equilibrium, player $i$ must receive at least $\\\\underline{v}_i$.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 6.6 Folk Theorem\\n\",\n    \"\\n\",\n    \"If players are sufficiently patient (i.e. $\\\\delta$ can be arbitrarily close to 1), then any feasible and individual rational payoff vector can be achieved as a Nash equilibrium of the repeated game.\\n\",\n    \"\\n\",\n    \"The proof involves constructing strategies similar to Grim trigger, in which all players will play the punishment strategies if any player deviates from the proposed strategy.\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# 7. More Topics On Game Theory\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 7.1 Stochastic Game\\n\",\n    \"\\n\",\n    \"  [MS&E 336 lec 4](http://web.stanford.edu/~rjohari/teaching/notes.html)\\n\",\n    \"  \\n\",\n    \"## 7.2 Learning Theory\\n\",\n    \"\\n\",\n    \"  [MS&E 336 lec 6-7 Fictitious Play](http://web.stanford.edu/~rjohari/teaching/notes.html)\\n\",\n    \"  \\n\",\n    \"  [more general](https://www.uni-heidelberg.de/md/awi/forschung/lecture_belief_based_learning.pdf)\\n\",\n    \"\\n\",\n    \"## 7.3 Cooporative Game Theory\\n\",\n    \"\\n\",\n    \"  [lec 23](https://www.youtube.com/watch?v=HF6Nik3EypE)\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.0\"\n  },\n  \"latex_envs\": {\n   \"LaTeX_envs_menu_present\": true,\n   \"autoclose\": false,\n   \"autocomplete\": true,\n   \"bibliofile\": \"biblio.bib\",\n   \"cite_by\": \"apalike\",\n   \"current_citInitial\": 1,\n   \"eqLabelWithNumbers\": true,\n   \"eqNumInitial\": 1,\n   \"hotkeys\": {\n    \"equation\": \"Ctrl-E\",\n    \"itemize\": \"Ctrl-I\"\n   },\n   \"labels_anchors\": false,\n   \"latex_user_defs\": false,\n   \"report_style_numbering\": false,\n   \"user_envs_cfg\": false\n  },\n  \"nbTranslate\": {\n   \"displayLangs\": [\n    \"*\"\n   ],\n   \"hotkey\": \"alt-t\",\n   \"langInMainMenu\": true,\n   \"sourceLang\": \"en\",\n   \"targetLang\": \"fr\",\n   \"useGoogleTranslate\": true\n  },\n  \"toc\": {\n   \"base_numbering\": 1,\n   \"nav_menu\": {},\n   \"number_sections\": true,\n   \"sideBar\": true,\n   \"skip_h1_title\": false,\n   \"title_cell\": \"Table of Contents\",\n   \"title_sidebar\": \"Contents\",\n   \"toc_cell\": false,\n   \"toc_position\": {},\n   \"toc_section_display\": true,\n   \"toc_window_display\": false\n  },\n  \"varInspector\": {\n   \"cols\": {\n    \"lenName\": 16,\n    \"lenType\": 16,\n    \"lenVar\": 40\n   },\n   \"kernels_config\": {\n    \"python\": {\n     \"delete_cmd_postfix\": \"\",\n     \"delete_cmd_prefix\": \"del \",\n     \"library\": \"var_list.py\",\n     \"varRefreshCmd\": \"print(var_dic_list())\"\n    },\n    \"r\": {\n     \"delete_cmd_postfix\": \") \",\n     \"delete_cmd_prefix\": \"rm(\",\n     \"library\": \"var_list.r\",\n     \"varRefreshCmd\": \"cat(var_dic_list()) \"\n    }\n   },\n   \"types_to_exclude\": [\n    \"module\",\n    \"function\",\n    \"builtin_function_or_method\",\n    \"instance\",\n    \"_Feature\"\n   ],\n   \"window_display\": false\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n","colorizedLines":null,"stylingDirectives":null,"csv":null,"csvError":null,"dependabotInfo":{"showConfigurationBanner":null,"configFilePath":null,"networkDependabotPath":"/dreadfullegion/Private-Study-and-Research-Notes/network/updates","dismissConfigurationNoticePath":"/settings/dismiss-notice/dependabot_configuration_notice","configurationNoticeDismissed":false,"repoAlertsPath":"/dreadfullegion/Private-Study-and-Research-Notes/security/dependabot","repoSecurityAndAnalysisPath":"/dreadfullegion/Private-Study-and-Research-Notes/settings/security_analysis","repoOwnerIsOrg":false,"currentUserCanAdminRepo":true},"displayName":"Introduction to Game Theory.ipynb","displayUrl":"https://notebooks.githubusercontent.com/view/ipynb?browser=safari&bypass_fastly=true&color_mode=auto&commit=28715bf1eaaa39becc1c47f69a82ce33debdc5d1&device=iphone&docs_host=https%3A%2F%2Fdocs.github.com&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f647265616466756c6c6567696f6e2f507269766174652d53747564792d616e642d52657365617263682d4e6f7465732f323837313562663165616161333962656363316334376636396138326365333364656264633564312f536f6369616c253230536369656e63652f496e74726f64756374696f6e253230746f25323047616d652532305468656f72792e6970796e623f746f6b656e3d414b5a555443344e56574a4d3547373750534847594e54455445423655&logged_in=true&nwo=dreadfullegion%2FPrivate-Study-and-Research-Notes&path=Social+Science%2FIntroduction+to+Game+Theory.ipynb&platform=ios&repository_id=159648187&repository_type=Repository&version=16","headerInfo":{"blobSize":"192 KB","deleteInfo":{"deletePath":"https://github.com/dreadfullegion/Private-Study-and-Research-Notes/delete/master/Social%20Science/Introduction%20to%20Game%20Theory.ipynb","deleteTooltip":"Delete this file"},"editInfo":{"editTooltip":"Edit this file"},"ghDesktopPath":"x-github-client://openRepo/https://github.com/dreadfullegion/Private-Study-and-Research-Notes?branch=master&filepath=Social%20Science%2FIntroduction%20to%20Game%20Theory.ipynb","gitLfsPath":null,"onBranch":true,"shortPath":"5fe32f9","siteNavLoginPath":"/login?return_to=https%3A%2F%2Fgithub.com%2Fdreadfullegion%2FPrivate-Study-and-Research-Notes%2Fblob%2Fmaster%2FSocial%2520Science%2FIntroduction%2520to%2520Game%2520Theory.ipynb","isCSV":false,"isRichtext":false,"toc":null,"lineInfo":{"truncatedLoc":"2379","truncatedSloc":"2379"},"mode":"file"},"image":false,"isCodeownersFile":null,"isValidLegacyIssueTemplate":false,"issueTemplateHelpUrl":"https://docs.github.com/articles/about-issue-and-pull-request-templates","issueTemplate":null,"discussionTemplate":null,"language":"Jupyter Notebook","large":false,"loggedIn":true,"newDiscussionPath":"/dreadfullegion/Private-Study-and-Research-Notes/discussions/new","newIssuePath":"/dreadfullegion/Private-Study-and-Research-Notes/issues/new","planSupportInfo":{"repoIsFork":null,"repoOwnedByCurrentUser":null,"requestFullPath":"/dreadfullegion/Private-Study-and-Research-Notes/blob/master/Social%20Science/Introduction%20to%20Game%20Theory.ipynb","showFreeOrgGatedFeatureMessage":null,"showPlanSupportBanner":null,"upgradeDataAttributes":null,"upgradePath":null},"publishBannersInfo":{"dismissActionNoticePath":"/settings/dismiss-notice/publish_action_from_dockerfile","dismissStackNoticePath":"/settings/dismiss-notice/publish_stack_from_file","releasePath":"/dreadfullegion/Private-Study-and-Research-Notes/releases/new?marketplace=true","showPublishActionBanner":false,"showPublishStackBanner":false},"renderImageOrRaw":false,"richText":null,"renderedFileInfo":{"identityUUID":"f58fe4fb-44f8-40d5-9fd3-99b8c11c678c","renderFileType":"ipynb","size":196936},"tabSize":8,"topBannersInfo":{"overridingGlobalFundingFile":false,"globalPreferredFundingPath":null,"repoOwner":"dreadfullegion","repoName":"Private-Study-and-Research-Notes","showInvalidCitationWarning":false,"citationHelpUrl":"https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/creating-a-repository-on-github/about-citation-files","showDependabotConfigurationBanner":null,"actionsOnboardingTip":null},"truncated":false,"viewable":true,"workflowRedirectUrl":null,"symbols":{"timedOut":false,"notAnalyzed":true,"symbols":[]}},"csrf_tokens":{"/dreadfullegion/Private-Study-and-Research-Notes/branches":{"post":"P5d7AyqlDSq9TcWOHZl4TIBbuK7C8lz_TFFSU3FqwuDsSPkUq2YR5nyFNw8-dz7wTGq0zbXDJE5IOAUDuT-HiQ"}}},"title":"Private-Study-and-Research-Notes/Social Science/Introduction to Game Theory.ipynb at master  dreadfullegion/Private-Study-and-Research-Notes","locale":"en"}